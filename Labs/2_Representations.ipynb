{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"celltoolbar":"Slideshow","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"livereveal":{"scroll":true,"start_slideshow_at":"selected","transition":"none"},"colab":{"name":"Representations.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"S8qEgXsSq0p4"},"source":["# Word Representations\n","\n","## *\"I know words. I have the best words!\"*\n","    - Noam Chomsky"]},{"cell_type":"markdown","metadata":{"id":"pz0lqC4Fq0p5"},"source":["## Discrete Sparse Representations"]},{"cell_type":"code","metadata":{"id":"ZE92W7EprB7j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615199021294,"user_tz":-60,"elapsed":6025,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}},"outputId":"9fa9e5b9-f6d2-46fc-e7ff-1b5318c3ea7e"},"source":["! pip install wget"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=41192c7e1977a32659dbb9c41593851e44e6fcc7725347abc65932e980c41dd6\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JOJIlxitrFQ1","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1615199021979,"user_tz":-60,"elapsed":6468,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}},"outputId":"9ebf4987-59a8-482d-97d4-a3e043539bee"},"source":["import wget\n","url = 'https://raw.githubusercontent.com/dirkhovy/NLPclass/master/data/reviews.full.tsv.zip'\n","wget.download(url, 'reviews.full.tsv.zip')"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'reviews.full.tsv.zip'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"KVcu0cGprgZr","executionInfo":{"status":"ok","timestamp":1615199022448,"user_tz":-60,"elapsed":6701,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}}},"source":["from zipfile import ZipFile\n","with ZipFile('reviews.full.tsv.zip', 'r') as zf:\n","    zf.extractall()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"QBmRyBAIq0p5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615199022978,"user_tz":-60,"elapsed":7096,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}},"outputId":"eef0cf87-34e4-4ad9-8fe7-652824714ef3"},"source":["import pandas as pd\n","df = pd.read_csv('reviews.full.tsv', sep='\\t', nrows=100000)\n","documents = df.text.tolist()\n","print(documents[:4])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[\"Prices change daily and if you want to really research the price continually at many different sites , I have found cheaper cars elsewhere . However , if you don ' t have a lot of time to research the price , this site has always been among the top three ( e . g ., cheapest ) of the ten sites I use to reserve a car .\", 'and the fact that they will match other companies is awesome !!', \"Used Paypal for my buying and selling for the past 0 years and never had an issue they didn ' t resolve to my satisfaction .\", \"I ' ve made two purchases on CJ ' s for Fallout : New Vegas and The Elder Scrolls V : Skyrim . I have been satisfied by both , being extremely cheaper than the Steam versions . The Autokey system that CJ ' s uses is genius . I recommend this site to anyone who is a PC gamer !\"]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lw___PhUq0p-","executionInfo":{"status":"ok","timestamp":1615199024263,"user_tz":-60,"elapsed":8085,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}}},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","small_vectorizer = CountVectorizer()\n","\n","sentences_2 = documents[:1]\n","\n","X1 = small_vectorizer.fit_transform(sentences_2)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"bcJRNG9_stYG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615199024275,"user_tz":-60,"elapsed":7924,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}},"outputId":"015f7d03-c336-4240-d707-8ab32a647fc3"},"source":["small_vectorizer"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n","                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n","                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n","                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n","                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n","                tokenizer=None, vocabulary=None)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"9iH56Q-cq0qA"},"source":["Let's implement this ourselves:"]},{"cell_type":"code","metadata":{"id":"CComYPqHq0qB","colab":{"base_uri":"https://localhost:8080/","height":100},"executionInfo":{"status":"ok","timestamp":1615199024277,"user_tz":-60,"elapsed":5248,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}},"outputId":"0c0fa28e-f240-4a57-e840-c33223b0371c"},"source":["import numpy as np\n","num_docs = 1\n","\n","# collect all word types (= vocabulary)\n","vocabulary = set()\n","for document in documents[:num_docs]:\n","    tokens = document.lower().split()\n","    vocabulary = vocabulary.union(set(tokens))\n","vocabulary = sorted(vocabulary)\n","\n","# create a data matrix with #docs-by-#features dimensions\n","X = np.zeros((num_docs, len(vocabulary)))\n","\n","# fill that matrix with sweet counts\n","for d, document in enumerate(documents[:num_docs]):\n","    tokens = document.lower().split()\n","    for i, feature in enumerate(vocabulary):\n","        X[d, i] = tokens.count(feature)\n","\n","# show the result as a DataFrame\n","pd.DataFrame(data=X, columns=vocabulary, dtype=int)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>'</th>\n","      <th>(</th>\n","      <th>)</th>\n","      <th>,</th>\n","      <th>.</th>\n","      <th>.,</th>\n","      <th>a</th>\n","      <th>always</th>\n","      <th>among</th>\n","      <th>and</th>\n","      <th>at</th>\n","      <th>been</th>\n","      <th>car</th>\n","      <th>cars</th>\n","      <th>change</th>\n","      <th>cheaper</th>\n","      <th>cheapest</th>\n","      <th>continually</th>\n","      <th>daily</th>\n","      <th>different</th>\n","      <th>don</th>\n","      <th>e</th>\n","      <th>elsewhere</th>\n","      <th>found</th>\n","      <th>g</th>\n","      <th>has</th>\n","      <th>have</th>\n","      <th>however</th>\n","      <th>i</th>\n","      <th>if</th>\n","      <th>lot</th>\n","      <th>many</th>\n","      <th>of</th>\n","      <th>price</th>\n","      <th>prices</th>\n","      <th>really</th>\n","      <th>research</th>\n","      <th>reserve</th>\n","      <th>site</th>\n","      <th>sites</th>\n","      <th>t</th>\n","      <th>ten</th>\n","      <th>the</th>\n","      <th>this</th>\n","      <th>three</th>\n","      <th>time</th>\n","      <th>to</th>\n","      <th>top</th>\n","      <th>use</th>\n","      <th>want</th>\n","      <th>you</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   '  (  )  ,  .  .,  a  always  ...  this  three  time  to  top  use  want  you\n","0  1  1  1  3  3   1  2       1  ...     1      1     1   3    1    1     1    2\n","\n","[1 rows x 51 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"ZTAJ3jpBq0qF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615199024279,"user_tz":-60,"elapsed":4928,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}},"outputId":"e7c5a5e1-d062-4017-894e-ec8a1bdd86fe"},"source":["vocabulary_ = {word: position for position, word in enumerate(vocabulary)}\n","vocabulary_"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{\"'\": 0,\n"," '(': 1,\n"," ')': 2,\n"," ',': 3,\n"," '.': 4,\n"," '.,': 5,\n"," 'a': 6,\n"," 'always': 7,\n"," 'among': 8,\n"," 'and': 9,\n"," 'at': 10,\n"," 'been': 11,\n"," 'car': 12,\n"," 'cars': 13,\n"," 'change': 14,\n"," 'cheaper': 15,\n"," 'cheapest': 16,\n"," 'continually': 17,\n"," 'daily': 18,\n"," 'different': 19,\n"," 'don': 20,\n"," 'e': 21,\n"," 'elsewhere': 22,\n"," 'found': 23,\n"," 'g': 24,\n"," 'has': 25,\n"," 'have': 26,\n"," 'however': 27,\n"," 'i': 28,\n"," 'if': 29,\n"," 'lot': 30,\n"," 'many': 31,\n"," 'of': 32,\n"," 'price': 33,\n"," 'prices': 34,\n"," 'really': 35,\n"," 'research': 36,\n"," 'reserve': 37,\n"," 'site': 38,\n"," 'sites': 39,\n"," 't': 40,\n"," 'ten': 41,\n"," 'the': 42,\n"," 'this': 43,\n"," 'three': 44,\n"," 'time': 45,\n"," 'to': 46,\n"," 'top': 47,\n"," 'use': 48,\n"," 'want': 49,\n"," 'you': 50}"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"5H5_vUwWq0qI"},"source":["The result is a *sparse count matrix*:"]},{"cell_type":"code","metadata":{"id":"gG81bVvdq0qJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615199024280,"user_tz":-60,"elapsed":4019,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}},"outputId":"aee71374-b5f3-4dd6-f19f-d63087ce2233"},"source":["# indexed representation\n","import numpy as np\n","# print(X1)\n","\n","# dense representation\n","print(X1.todense())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 2 2 1 1 2 1 1 2 1 4 1 1 1 3\n","  1 1 1 2]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FrdF2czAq0qN"},"source":["We can access the mapping from vector position to feature names via `get_feature_names()`:"]},{"cell_type":"code","metadata":{"id":"YrsaRKnyq0qO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615199024282,"user_tz":-60,"elapsed":3593,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}},"outputId":"bfdf838c-67d5-45e8-cd3a-7a9673a89ed1"},"source":["print(small_vectorizer.get_feature_names())"],"execution_count":11,"outputs":[{"output_type":"stream","text":["['always', 'among', 'and', 'at', 'been', 'car', 'cars', 'change', 'cheaper', 'cheapest', 'continually', 'daily', 'different', 'don', 'elsewhere', 'found', 'has', 'have', 'however', 'if', 'lot', 'many', 'of', 'price', 'prices', 'really', 'research', 'reserve', 'site', 'sites', 'ten', 'the', 'this', 'three', 'time', 'to', 'top', 'use', 'want', 'you']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aVdgUWsIq0qR"},"source":["The inverse (the mapping from feature names to vector positions) is encoded as a list in `vocabulary_`:"]},{"cell_type":"code","metadata":{"id":"k8njLadhq0qS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615199024284,"user_tz":-60,"elapsed":2717,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}},"outputId":"d31404fa-8701-44c4-c891-487b5b9d9a44"},"source":["print(small_vectorizer.vocabulary_)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["{'prices': 24, 'change': 7, 'daily': 11, 'and': 2, 'if': 19, 'you': 39, 'want': 38, 'to': 35, 'really': 25, 'research': 26, 'the': 31, 'price': 23, 'continually': 10, 'at': 3, 'many': 21, 'different': 12, 'sites': 29, 'have': 17, 'found': 15, 'cheaper': 8, 'cars': 6, 'elsewhere': 14, 'however': 18, 'don': 13, 'lot': 20, 'of': 22, 'time': 34, 'this': 32, 'site': 28, 'has': 16, 'always': 0, 'been': 4, 'among': 1, 'top': 36, 'three': 33, 'cheapest': 9, 'ten': 30, 'use': 37, 'reserve': 27, 'car': 5}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GcGFh3TAq0qV"},"source":["## Terminology \n","\n","![](matrix.pdf)"]},{"cell_type":"markdown","metadata":{"id":"v0UaB0J2q0qV"},"source":["Let's redo this for the entire corpus:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"kt-LgZ3Jq0qW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615199025598,"user_tz":-60,"elapsed":2556,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}},"outputId":"13523a7f-24f3-4f07-ba3f-cdc67c2b741f"},"source":["vectorizer = CountVectorizer(analyzer='word', \n","                             ngram_range=(1, 2), \n","                             min_df=0.001, \n","                             max_df=0.75, \n","                             stop_words='english')\n","\n","X = vectorizer.fit_transform(documents[:10000])\n","\n","print(X.shape)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["(10000, 3869)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i7T1-uUWq0qb"},"source":["Calling `transform()` on a new document will apply the vocabulary we collected previously to this new data point. Any words we have not seen before are ignored.\n"]},{"cell_type":"code","metadata":{"id":"NTlBV_boq0qb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615199025600,"user_tz":-60,"elapsed":2167,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}},"outputId":"6f1a4eef-5ce4-4c20-8b14-8de654810fd7"},"source":["vectorizer.transform([documents[-1]])"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<1x3869 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 8 stored elements in Compressed Sparse Row format>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"6RHwg27fq0qe","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1615199025602,"user_tz":-60,"elapsed":1978,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}},"outputId":"31dc0a99-b727-44ee-cf86-e9f1227b4d25"},"source":["documents[-1]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Never had any issues , easy to use and great prices .'"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"hiDyZpFjq0qh"},"source":["## Exercise\n","\n","Use vector operations to find out \n","- what the 5 most frequent words are in `X`\n","- in how many different documents the word `delivery` occurs\n","- what percentage of the overall corpus that number corresponds to"]},{"cell_type":"code","metadata":{"id":"pPdQ8CTCq0qi","executionInfo":{"status":"ok","timestamp":1615199025603,"user_tz":-60,"elapsed":1594,"user":{"displayName":"Debora Nozza","photoUrl":"","userId":"08904684087232240081"}}},"source":["# your code here"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D7HxcwCmq0ql"},"source":["## Character $n$-grams\n","\n","We can also use characters to analyze text:"]},{"cell_type":"code","metadata":{"id":"Rlq4fIv1q0ql"},"source":["char_vectorizer = CountVectorizer(analyzer='char', \n","                                  ngram_range=(2, 6), \n","                                  min_df=0.001, \n","                                  max_df=0.75)\n","\n","C = char_vectorizer.fit_transform(documents[:10])\n","C"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_cuDmd_q0qn"},"source":["print(char_vectorizer.vocabulary_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q2gXCFzRq0qq"},"source":["## Syntactic $n$-grams"]},{"cell_type":"code","metadata":{"id":"8hyW626mq0qq"},"source":["import spacy\n","nlp = spacy.load('en')\n","\n","features = [' '.join([\"{}_{}\".format(c.lemma_, c.head.lemma_) \n","                      for c in nlp(sentence)])\n","            for sentence in documents[:100]]\n","\n","syntax_vectorizer = CountVectorizer()\n","X = syntax_vectorizer.fit_transform(features)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ALdDdJQ4sfXe"},"source":["print(documents[0])\n","print(features[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"v9TuOfqOq0qs"},"source":["print(syntax_vectorizer.vocabulary_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MHFbQYr9q0qu"},"source":["# Dense Distributed Representations"]},{"cell_type":"markdown","metadata":{"id":"GCb0XwVwq0qv"},"source":["## Word embeddings with `Word2vec`"]},{"cell_type":"code","metadata":{"id":"NpSgRnn_q0qv"},"source":["from gensim.models import Word2Vec\n","from gensim.models.word2vec import FAST_VERSION\n","\n","corpus = [document.split() for document in documents]\n","\n","# initialize model\n","w2v_model = Word2Vec(size=100,\n","                     window=15,\n","                     sample=0.0001,\n","                     iter=200,\n","                     negative=5, \n","                     min_count=100,\n","                     workers=-1, \n","                     hs=0\n",")\n","\n","w2v_model.build_vocab(corpus)\n","\n","w2v_model.train(corpus, \n","                total_examples=w2v_model.corpus_count, \n","                epochs=w2v_model.epochs)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kZ1T6b1htLRQ"},"source":["print(corpus[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ph7ZnnwTq0qx"},"source":["Now, we can use the embeddings of the model"]},{"cell_type":"code","metadata":{"id":"IZl3-J06q0qy"},"source":["w2v_model.wv['delivery']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"geYn64tsq0qz"},"source":["w2v_model.wv.most_similar(['delivery','concert'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"oQQLNlOrq0q2"},"source":["# birthday - present + husband => birthday:present as husband:?\n","w2v_model.wv.most_similar(positive=['birthday', 'husband'], negative=['present'], topn=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1alOWRHcq0q4"},"source":["word1 = \"Cheapest\"\n","word2 = \"friendly\"\n","\n","# retrieve the actual vector\n","# print(w2v_model.wv[word1])\n","\n","# compare\n","print(w2v_model.wv.similarity(word1, word2))\n","\n","# get the 3 most similar words\n","print(w2v_model.wv.most_similar(word1, topn=3))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z_P7sWZOq0q8"},"source":["\n","### Exercise\n","Use `spacy` to restrict the words in the tweets to *content words*, i.e., nouns, verbs, and adjectives. Transform the words to lower case and add the POS with an underderscore. E.g.:\n","\n","`love_VERB old-fashioneds_NOUN`\n","\n","This also allows us to distinguish between homographs, i.e., words that are written the same, but belong to different word classes, e.g., *love* in \"I **love** old-fashioneds\" vs. \"He felt so sick, it must have been **love**\".\n","\n","\n","Make sure to exclude sentences that contain none of the above.\n","\n","Write the resulting corpus to a variable called `word_corpus`."]},{"cell_type":"code","metadata":{"id":"oghTQmmAq0q8"},"source":["# Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IWJom385q0q-"},"source":["Rerun the `Word2vec` model from above on the new data set and test the words out"]},{"cell_type":"code","metadata":{"id":"BNlrX5LGq0q_"},"source":["# Your code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"inphqYJFq0rD"},"source":["## Exercise\n","\n","Train 4 more `Word2vec` models and average the resulting embedding matrices."]},{"cell_type":"code","metadata":{"id":"R6FRlFh4q0rD"},"source":["# Your code here\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Al2nC2zUq0rF"},"source":["## Document embeddings with `Doc2Vec`"]},{"cell_type":"code","metadata":{"id":"LUuNgYdnq0rF"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LB8xMlJDq0rH"},"source":["from gensim.models import Doc2Vec\n","from gensim.models.doc2vec import FAST_VERSION\n","from gensim.models.doc2vec import TaggedDocument\n","\n","corpus = []\n","\n","for row in df.iterrows():\n","    label = row[1].score\n","    text = row[1].text\n","    corpus.append(TaggedDocument(words=text.split(), tags=[str(label)]))\n","\n","print('done')\n","d2v_model = Doc2Vec(vector_size=100, \n","                    window=15,\n","                    hs=0,\n","                    sample=0.000001,\n","                    negative=5,\n","                    min_count=100,\n","                    workers=-1,\n","                    epochs=500,\n","                    dm=0, \n","                    dbow_words=1)\n","\n","d2v_model.build_vocab(corpus)\n","\n","d2v_model.train(corpus, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tn87gc7Zq0rI"},"source":["We can now look at the elements"]},{"cell_type":"code","metadata":{"id":"Pm1NgMk0w_U5"},"source":["d2v_model.docvecs[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Az6y7ckIq0rJ"},"source":["d2v_model.docvecs.doctags"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s16KBUefq0rL"},"source":["target_doc = '1'\n","\n","similar_docs = d2v_model.docvecs.most_similar(target_doc, topn=5)\n","print(similar_docs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LV8VauPpq0rM"},"source":["## Exercise\n","\n","What are the 10 most similar ***words*** to each category?"]},{"cell_type":"code","metadata":{"id":"BFkB9eJbq0rN"},"source":["# your code here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Iz4klYRq0rO"},"source":[""],"execution_count":null,"outputs":[]}]}