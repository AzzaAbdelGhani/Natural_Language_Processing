{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "nbpresent": {
      "slides": {
        "3e606cca-ddab-4b87-8295-f1cca7962a9d": {
          "id": "3e606cca-ddab-4b87-8295-f1cca7962a9d",
          "prev": "8921ba99-3b08-4f47-affd-b6f8fadaa8cd",
          "regions": {
            "cb08d0e1-9b2e-4940-95dc-76a8f9e75b03": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "67ca55d4-28b9-410e-9921-08d943aa3151",
                "part": "whole"
              },
              "id": "cb08d0e1-9b2e-4940-95dc-76a8f9e75b03"
            }
          }
        },
        "8921ba99-3b08-4f47-affd-b6f8fadaa8cd": {
          "id": "8921ba99-3b08-4f47-affd-b6f8fadaa8cd",
          "prev": null,
          "regions": {
            "48e51b5b-c219-4946-bad8-4b170ff7da1b": {
              "attrs": {
                "height": 0.8,
                "width": 0.8,
                "x": 0.1,
                "y": 0.1
              },
              "content": {
                "cell": "ad90604f-afeb-4baa-b940-c3a1f3de8891",
                "part": "whole"
              },
              "id": "48e51b5b-c219-4946-bad8-4b170ff7da1b"
            }
          }
        }
      },
      "themes": {}
    },
    "colab": {
      "name": "8_The_Perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nbpresent": {
          "id": "ad90604f-afeb-4baa-b940-c3a1f3de8891"
        },
        "id": "73Hc-kE_dGmU"
      },
      "source": [
        "# The Perceptron\n",
        "is the building-block of a Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT-_mJ05dGmU"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sbs\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "sbs.set_context('notebook')\n",
        "\n",
        "#activation functions:\n",
        "def sigmoid(x):\n",
        "    '''\n",
        "    ranges from  0 to 1\n",
        "    '''\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    '''\n",
        "    ranges from  0 to 1\n",
        "    '''\n",
        "    return np.where(x > 0, x, 0)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILDpSVU_dGmZ"
      },
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, num_inputs):\n",
        "        self.w1 = np.random.random(num_inputs) #weights matrix\n",
        "        self.b1 = 1 #bias\n",
        "        #in this case, single layer perceptron, one weight matrix and one bias term\n",
        "    \n",
        "    def predict(self, X):\n",
        "        # compute activation for input layer\n",
        "        activation = np.dot(X, self.w1) + self.b1\n",
        "        # non-linear transform\n",
        "        fX = sigmoid(activation)\n",
        "        # check threshold: for sigmoid and relu, use 0.5, for tanh, use 0\n",
        "        y = np.where(fX >= 0.5, 1, -1)\n",
        "        return y\n",
        "    \n",
        "    def fit(self, train_data, train_labels, num_epochs=20):\n",
        "        models = []\n",
        "        print(\"N. epochs\",num_epochs)\n",
        "        for epoch in range(1, num_epochs+1):\n",
        "            print(\"Epoch:\",epoch)\n",
        "            for (X, y) in zip(train_data, train_labels):\n",
        "                pred_label = self.predict(X)\n",
        "\n",
        "                if pred_label != y:\n",
        "                    print('update')\n",
        "                    self.w1 = self.w1 + (X * y)\n",
        "                    self.b1 = self.b1 + y\n",
        "\n",
        "            models.append((self.w1, self.b1))\n",
        "\n",
        "        return models"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXYDIQnpdGmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f88870-18a8-41af-8dba-100ba08fb459"
      },
      "source": [
        "# AND perceptron\n",
        "perceptron = Perceptron(2)\n",
        "\n",
        "and_data = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
        "and_labels = np.array([1, -1, -1, -1], dtype=np.int)\n",
        "\n",
        "iters = perceptron.fit(and_data, and_labels, num_epochs=10)\n",
        "and_predictions = perceptron.predict(and_data)\n",
        "\n",
        "print(and_predictions)\n",
        "\n",
        "print(\"Accuracy\",accuracy_score(and_labels, and_predictions))\n",
        "print()\n",
        "print(\"Iterations:\")\n",
        "print(iters)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N. epochs 10\n",
            "Epoch: 1\n",
            "update\n",
            "update\n",
            "Epoch: 2\n",
            "update\n",
            "update\n",
            "Epoch: 3\n",
            "update\n",
            "update\n",
            "update\n",
            "Epoch: 4\n",
            "update\n",
            "update\n",
            "Epoch: 5\n",
            "update\n",
            "update\n",
            "Epoch: 6\n",
            "Epoch: 7\n",
            "Epoch: 8\n",
            "Epoch: 9\n",
            "Epoch: 10\n",
            "[ 1 -1 -1 -1]\n",
            "Accuracy 1.0\n",
            "\n",
            "Iterations:\n",
            "[(array([-0.2307137 , -0.27797877]), -1), (array([-0.2307137 ,  0.72202123]), -1), (array([-0.2307137 ,  0.72202123]), -2), (array([0.7692863 , 0.72202123]), -2), (array([0.7692863 , 1.72202123]), -2), (array([0.7692863 , 1.72202123]), -2), (array([0.7692863 , 1.72202123]), -2), (array([0.7692863 , 1.72202123]), -2), (array([0.7692863 , 1.72202123]), -2), (array([0.7692863 , 1.72202123]), -2)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_gni7mTdGmg"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Create OR data and rerun the perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruF3cALZdGmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3bb9585-1d0e-40b2-f6f4-5f245ce5f854"
      },
      "source": [
        "# OR perceptron\n",
        "perceptron = Perceptron(2)\n",
        "\n",
        "or_data = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
        "or_labels = np.array([1, 1, 1, -1], dtype=np.int)\n",
        "\n",
        "iters = perceptron.fit(or_data, or_labels, num_epochs=10)\n",
        "or_predictions = perceptron.predict(or_data)\n",
        "\n",
        "print(or_predictions)\n",
        "\n",
        "print(\"Accuracy\",accuracy_score(or_labels, or_predictions))\n",
        "print()\n",
        "print(\"Iterations:\")\n",
        "print(iters)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N. epochs 10\n",
            "Epoch: 1\n",
            "update\n",
            "Epoch: 2\n",
            "update\n",
            "Epoch: 3\n",
            "update\n",
            "update\n",
            "Epoch: 4\n",
            "update\n",
            "update\n",
            "Epoch: 5\n",
            "Epoch: 6\n",
            "Epoch: 7\n",
            "Epoch: 8\n",
            "Epoch: 9\n",
            "Epoch: 10\n",
            "[ 1  1  1 -1]\n",
            "Accuracy 1.0\n",
            "\n",
            "Iterations:\n",
            "[(array([0.94885501, 0.28632564]), 0), (array([0.94885501, 0.28632564]), -1), (array([1.94885501, 0.28632564]), -1), (array([1.94885501, 1.28632564]), -1), (array([1.94885501, 1.28632564]), -1), (array([1.94885501, 1.28632564]), -1), (array([1.94885501, 1.28632564]), -1), (array([1.94885501, 1.28632564]), -1), (array([1.94885501, 1.28632564]), -1), (array([1.94885501, 1.28632564]), -1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhRozQCedGmn"
      },
      "source": [
        "But what about the XOR?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWD_FJaZdGmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85c2ae8-a1d2-4ff6-f013-06e796a39ed1"
      },
      "source": [
        "# XOR perceptron\n",
        "perceptron = Perceptron(2)\n",
        " \n",
        "xor_data = np.array([[1, 1], [1, 0], [0, 1], [0, 0]])\n",
        "xor_labels = np.array([1, -1, -1, 1], dtype=np.int)\n",
        " \n",
        "iters = perceptron.fit(xor_data, xor_labels, num_epochs=10)\n",
        "xor_predictions = perceptron.predict(xor_data)\n",
        " \n",
        "print(xor_predictions)\n",
        " \n",
        "print(\"Accuracy\",accuracy_score(xor_labels, xor_predictions))\n",
        "print()\n",
        "print(\"Iterations:\")\n",
        "print(iters)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N. epochs 10\n",
            "Epoch: 1\n",
            "update\n",
            "update\n",
            "update\n",
            "Epoch: 2\n",
            "update\n",
            "update\n",
            "update\n",
            "update\n",
            "Epoch: 3\n",
            "update\n",
            "update\n",
            "update\n",
            "update\n",
            "Epoch: 4\n",
            "update\n",
            "update\n",
            "update\n",
            "update\n",
            "Epoch: 5\n",
            "update\n",
            "update\n",
            "update\n",
            "update\n",
            "Epoch: 6\n",
            "update\n",
            "update\n",
            "update\n",
            "update\n",
            "Epoch: 7\n",
            "update\n",
            "update\n",
            "update\n",
            "update\n",
            "Epoch: 8\n",
            "update\n",
            "update\n",
            "update\n",
            "update\n",
            "Epoch: 9\n",
            "update\n",
            "update\n",
            "update\n",
            "update\n",
            "Epoch: 10\n",
            "update\n",
            "update\n",
            "update\n",
            "update\n",
            "[-1 -1 -1  1]\n",
            "Accuracy 0.75\n",
            "\n",
            "Iterations:\n",
            "[(array([-0.25024573, -0.08589894]), 0), (array([-0.25024573, -0.08589894]), 0), (array([-0.25024573, -0.08589894]), 0), (array([-0.25024573, -0.08589894]), 0), (array([-0.25024573, -0.08589894]), 0), (array([-0.25024573, -0.08589894]), 0), (array([-0.25024573, -0.08589894]), 0), (array([-0.25024573, -0.08589894]), 0), (array([-0.25024573, -0.08589894]), 0), (array([-0.25024573, -0.08589894]), 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAbIRP8AdGmp"
      },
      "source": [
        "Perceptrons are **linear classifiers**. I.e., they can only find a perfect fit to **linearly seperable data**\n",
        "\n",
        "If only first order features are used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbpresent": {
          "id": "67ca55d4-28b9-410e-9921-08d943aa3151"
        },
        "id": "DGBLHfmjdGmq"
      },
      "source": [
        "# Multilayer perceptron to the rescue!\n",
        "- Data that is distributed non-linearly (e.g. XOR) cannot be learned by perceptron\n",
        "- At least not without tedious feature engineering\n",
        "\n",
        "**Stacking several perceptrons increases expressive power!**\n",
        "\n",
        "- learning intermediate/partial representations at intermediate layers\n",
        "\n",
        "**Let's see how it works in `keras`**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5KnKFU8LAtC"
      },
      "source": [
        "<img src=\"https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png\" width=\"20%\" />\n",
        "\n",
        "## Keras: Deep Learning library for Theano and TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0F3172rLAtE"
      },
      "source": [
        ">Keras is a minimalist, highly modular neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. \n",
        "\n",
        ">It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
        "ref: https://keras.io/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hls6HsrFdGmr"
      },
      "source": [
        "def gaussian_data(num, epsilon=1):\n",
        "    '''\n",
        "    generates a data set from two overlapping Gaussian point clouds\n",
        "    '''\n",
        "    x1_p1 = np.random.normal(1 + epsilon, size=num//2)\n",
        "    x2_p1 = np.random.normal(1, size=num//2)\n",
        "\n",
        "    x1_p2 = np.random.normal(-(1 + epsilon), size=num//2)\n",
        "    x2_p2 = np.random.normal(-(1 + epsilon), size=num//2)\n",
        "\n",
        "    x1 = np.concatenate([x1_p1, x1_p2])\n",
        "    x2 = np.concatenate([x2_p1, x2_p2])\n",
        "\n",
        "    labels = np.zeros((num, 2))\n",
        "    labels[:num//2, 0] = 1\n",
        "    labels[num//2:, 1] = 1\n",
        "    return x1, x2, labels\n",
        "\n",
        "def XOR_sample(sample_size, ratio=0.5, x1_p1_mean=25, x1_p2_mean=50, x2_p1_mean=5, x2_p2_mean=2, epsilon = 0.1):\n",
        "    size1 = int(sample_size * ratio)\n",
        "    size2 = sample_size - size1\n",
        "    \n",
        "    x1 = np.random.normal(loc=x1_p1_mean, size=size1//2)\n",
        "    x1 = np.hstack((x1, np.random.normal(loc=-x1_p1_mean, size=size1//2)))   \n",
        "    x1 = np.hstack((x1, np.random.normal(loc=x1_p2_mean, size=size2//2)))\n",
        "    x1 = np.hstack((x1, np.random.normal(loc=-x1_p2_mean, size=size2//2)))\n",
        "    \n",
        "    x2 = np.random.normal(loc=x2_p1_mean, size=size1//2)\n",
        "    x2 = np.hstack((x2, np.random.normal(loc=-x2_p1_mean, size=size1//2)))\n",
        "    x2 = np.hstack((x2, np.random.normal(loc=x2_p2_mean, size=size2//2)))\n",
        "    x2 = np.hstack((x2, np.random.normal(loc=-x2_p2_mean, size=size2//2)))\n",
        "    \n",
        "    labels = np.zeros((sample_size, 2))\n",
        "    labels[:sample_size//2, 0] = 1\n",
        "    labels[sample_size//2:, 1] = 1\n",
        "\n",
        "    return x1, x2, labels\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVQo3yvudGmt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "d08e0a0c-95d7-4a1f-dc27-1e034d0da1dc"
      },
      "source": [
        "# let's get some data\n",
        "num_samples = 5000\n",
        "half = num_samples//2\n",
        "a,b,y = XOR_sample(num_samples)\n",
        "\n",
        "X = np.vstack((a,b)).T\n",
        "\n",
        "pd.DataFrame({'x1': a, 'x2': b}).plot.scatter(x='x1', y='x2', c=['red']*half + ['blue']*half);"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkFcbt9DP_6g",
        "outputId": "6f7f7db6-f303-4e42-f6ed-8d7aad4b5ade"
      },
      "source": [
        "X"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 23.99389831,   4.98460959],\n",
              "       [ 23.11841405,   5.46214899],\n",
              "       [ 25.1184894 ,   5.44340871],\n",
              "       ...,\n",
              "       [-50.05588257,  -2.88181392],\n",
              "       [-47.92897669,  -0.52609888],\n",
              "       [-49.45062966,  -0.90462926]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TfvxGLhQDry",
        "outputId": "2421c86e-ed60-42e8-9af1-8a062095fe2e"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHWoe10DuA-u",
        "outputId": "d3a15cbf-2f40-41ee-80b0-2b93f8c49fc1"
      },
      "source": [
        "y"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7cJ_LvvQPwO",
        "outputId": "bbb65aba-0c09-481c-fd4e-14c0b1813fab"
      },
      "source": [
        "y.shape #2:two classes (red and blue)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk_kF4cFdGmv"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "\n",
        "# input: a sequence  of 2 integers\n",
        "main_input = Input(shape=(2, ), name='main_input')\n",
        "\n",
        "# add the output layer\n",
        "output = Dense(2, activation='hard_sigmoid', name='output', kernel_initializer='glorot_uniform')(main_input)\n",
        "\n",
        "# f(X) = sigmoid(X*W + b)\n",
        "\n",
        "# the model is specified by connecting input and output\n",
        "perceptron_keras = Model(inputs=[main_input], outputs=[output])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGAquco5dGmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c588350-7071-4c47-f999-5dce2e4981f0"
      },
      "source": [
        "perceptron_keras.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "main_input (InputLayer)      [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 2)                 6         \n",
            "=================================================================\n",
            "Total params: 6\n",
            "Trainable params: 6\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM6fjB4PdGmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb7b83c-dcd4-4bc4-d831-9687e07ed08d"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "#training\n",
        "perceptron_keras.compile(loss='binary_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])#-->to evaluate the model through the training\n",
        "\n",
        "history = perceptron_keras.fit(X, y,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.2 # test data\n",
        "                )\n",
        "\n",
        "loss, accuracy = perceptron_keras.evaluate(X, y,\n",
        "                                           batch_size=20, \n",
        "                                           verbose=1)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 7.3719 - accuracy: 0.6371 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/15\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 7.6787 - accuracy: 0.6360 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/15\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 7.6791 - accuracy: 0.6194 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/15\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 7.6793 - accuracy: 0.6221 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/15\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 7.6788 - accuracy: 0.6253 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/15\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 7.6798 - accuracy: 0.6188 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/15\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 7.6793 - accuracy: 0.6341 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/15\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 7.6798 - accuracy: 0.6102 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/15\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 7.6803 - accuracy: 0.6299 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/15\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 7.6782 - accuracy: 0.6360 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/15\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 7.6792 - accuracy: 0.6220 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/15\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 7.6792 - accuracy: 0.6220 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/15\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 7.6802 - accuracy: 0.6254 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/15\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 7.6794 - accuracy: 0.6351 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/15\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 7.6801 - accuracy: 0.6207 - val_loss: 7.6246 - val_accuracy: 0.0000e+00\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 7.6685 - accuracy: 0.5000\n",
            "Test loss: 7.668547630310059\n",
            "Test accuracy: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyvAGARxdGm2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "f40df378-2d9c-4b43-f3b9-c4384f855556"
      },
      "source": [
        "pd.DataFrame(history.history).plot.line()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f682cbe3f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD9CAYAAAB3ECbVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbQklEQVR4nO3dfXRU5bn38e+VDCFLQGMjNbWxB0VAEQwFtcA5FBB8F+iRRwsiL1JXC3SJuIqttJ7S8xxKsaUVfAP0MfIisEq1q3oQ9cASbKJHxSX2oEejaGgbWlAjQV5MIMn1/JEhDWPCzOAMMzf+PmvNmpm97733lYH9y849e9/b3B0REQlDTqYLEBGRxCm0RUQCotAWEQmIQltEJCAKbRGRgCi0RUQCklBom9k1ZrbFzF43sz+Z2bXpLkxERD7L4p2nbWYGfAwMcvc3zOwC4AXgFHdvjLNse+Ai4O9AQ2pKFhE54eUCXwE2u3tdyxmRBFfQCJwSfV0A/D02sM2sIDqvpQuB3yVdroiIAAwCyltOiBva7u5mdj3whJntBzoBV7XSdAYwu7V1lJWVUVxcnHy5IiJfQFVVVQwaNAiaeimOEDe0zSwCzAJGufsLZvbPwBoz6+nu+1o0XQAsjVm8GCgrLi6mS5cux1i+iMgX1me6lRPpHukDnOHuLwBEg3s/cB6w+XAjd68Balou2NQdLiIiqZLI2SNVQLGZ9QAws/OA04H30lmYiIh8ViJ92jvNbCrwmJkd/vJxsrt/nN7SREQkVkJnj7j7SmBlmmsREZE4dEWkiEhAEj1P+4Th7ui+DyJyPJil/oSMYEO7odHZ8+khag4cpObTQ+w5cIiaTw+ye/+h6Pum6TUH/tGm5sAhPqk9pNAWkePi7f+4gvx2uSldZ9aG9nf+807+su9d6huc+sboo6HxiOe2mEFuTg6RHGt6dMwhcrLxpRyjc65h6FREEUmvwnZdiORcmfL1Zm1ov/m3T/ik8dN/hG+uEcnNIb9d9HXL6Tk50eem17m5imURyaxzv3QqkdzUf22YtaG9YdJvOKldLjk5il8RkcOyNrQ7ts/a0kREMkan/ImIBEShLSISEIW2iEhAFNoiIgFRaIuIBEShLSISEIW2iEhAFNoiIgFRaIuIBEShLSISkETuxt4F+EOLSQXAye7+pTTVJCIibUjkHpHbabojOwBmtiCR5UREJPWSCl8zywPGAZe3Mq+ApqPwloqPvTQREYmV7BHzSGCHu7/WyrwZwOzPX5KIiLQl2dCeDJS2MW8BsDRmWjFQluQ2RESkDQmHtpl9FRgMjG9tvrvXADUxy3yu4kRE5EjJnPI3EXjK3avTVYyIiBxdMqE9iba7RkRE5DhIuHvE3bunsxAREYlPV0SKiAREoS0iEhCFtohIQBTaIiIBUWiLiAREoS0iEhCFtohIQBTaIiIBUWiLiAREoS0iEhCFtohIQBTaIiIBUWiLiAREoS0iEhCFtohIQBTaIiIBUWiLiAQkodA2s3wzW2Rm75rZVjN7MN2FiYjIZyV6u7FfArVAd3d3Mzs9jTWJiEgb4oa2mXUEJgDF7u4A7r6rlXYFQEHM5OJUFCkiIk0S6R7pClQDs83sVTPbZGb/0kq7GUBlzKMsZZWKiEhCoZ0LnA1scfcLgR8Bvzezk2PaLQDOinkMSmGtIiJfeIn0af8FqAdWA7j7y2b2EdAdePVwI3evAWpaLmhmqatURETiH2m7+0fARuBSADPrDnwZ2Jbe0kREJFaiZ49MAUrN7NfAIWB89MhaRESOo4RC293fB4aktxQREYlHV0SKiAREoS0iEhCFtohIQBTaIiIBUWiLiAREoS0iEhCFtohIQBTaIiIBUWiLiAREoS0iEhCFtohIQBTaIiIBUWiLiAREoS0iEhCFtohIQBTaIiIBSegmCGa2HaiNPgB+5O7PpqsoEUnOoUOHqKqqora2Nn5jyRr5+fkUFxfTrl27hJdJ9HZjAP/H3d9IviwRSbeqqio6depEly5ddEPtQLg71dXVVFVVcdZZZyW8nLpHRE4AtbW1FBYWKrADYmYUFhYm/ddRMkfaK63pf0Q58OPYG/uaWQFQELNMcVLViMgxU2CH51j+zRI90h7k7iXARYAB97XSZgZQGfMoS7oiERFpU0Kh7e5/jT7XAQ8A/9xKswXAWTGPQakpU0RCYmbs27cv02WckOJ2j5hZByDi7nui3SNjgNdj20W7S2K7TFJVp4iIkNiR9unAJjP7H+ANoDswLa1VicgJY/PmzQwYMIALLriAAQMGsHnzZgA++OADhg8fTu/evenduze33XYbAC+++CJ9+/alT58+nH/++axevTqT5WeduEfa7v4+8PXjUIuIpMC//+eb/O/fPknLunuecTKzR5yfcPuDBw8yevRoHnnkEYYNG8aGDRsYPXo027ZtY+XKlXTt2pUNGzYAsHv3bgDuuusubr/9dsaOHYu7s2fPnrT8LKHSKX8ikjYVFRXk5eUxbNgwAIYPH05eXh4VFRX079+fp59+mttvv521a9fSsWNHAIYOHcqcOXOYM2cOr7zyCgUFsSelfbElc8qfiAQgmSPhTBowYABbtmxh/fr1rFixgnnz5lFeXs6MGTMYMWIEGzZs4JZbbuGyyy5jzpw5mS43ayi0RSRtevTowcGDB9m4cSNDhw7lueee49ChQ/To0YPKykqKi4sZM2YMgwYN4pxzzqGxsZFt27bRvXt3unbtSseOHVm2bFmmf4ysotAWkbTJy8vj8ccfZ/r06ezfv58OHTrw2GOPkZeXx6ZNm/jNb35Dbm4ujY2NLF68mJycHO655x42btxIXl4e7du359577830j5FVzN3Tt3KzLkBlZWUlXbp0Sdt2RL7o3nrrLc4777xMlyHHoLV/u+3btx8ej+Qsd9/ecp6+iBQRCYhCW0QkIAptEZGAKLRFRAKi0BYRCYhCW0QkIAptEZGAKLRFRAKi0BaR4NXX12e6hONGl7GLnGievgN2bk3Puot6w5Xz4jYbN24cFRUV1NXVcc4551BaWsqpp55KaWkpCxcuBJoucV+7di2nn346a9eu5Wc/+xmHDh0iJyeHZcuWcfLJJ3PhhRfy0UcfAU1XCR5+f/j1pEmTeO655/jud79Lt27duPPOO6mtraW+vp6f/OQnjBkzBoAdO3Ywffp03n33XQDGjh3LxIkT6devH5WVleTn5wMwcuRIxowZww033JCOTy8lFNoiknILFy7ktNNOA+DOO+/krrvu4oorrmDu3LmUl5dTVFTEvn37iEQivPPOO9x8882UlZXRrVs36urqOHjwINXV1UfdRnV1NRdddBHz588HmsbjLi8vJzc3l127dtGvXz8uv/xyTj31VG688UauuuoqHn/8cQA++ugjTjvtNAYPHsxvf/tbJk6cyPbt23n11Vd57LHH0vvhfE4KbZETTQJHwum2fPlyVq5cycGDB9m/fz/du3enoaGBCRMmUFRUBNA8fvb69eu56qqr6NatGwDt27enffv2cUM7Pz+f66+/vvn9hx9+yOTJk3n33XeJRCJ8/PHHVFRU0KtXL1588UXWr1/f3PbwL5Tp06dz2223MXHiRBYvXszkyZPJy8tL6WeRakn1aZvZbDNzM+uVroJEJGxlZWUsWrSIZ555hq1btzJnzhxqa2uTXk8kEqGxsbH5few6OnTocMR9aKdOncqQIUPYunUrr7/+OsXFxXG3O3DgQBoaGnjhhRdYunQp3/ve95Ku83hLOLTNrC/QH/hz+soRkdDV1NRwyimnUFhYSF1dHaWlpQBcffXVLF++nF27dgGwb98+amtrueyyy1i3bl1zf3NdXR179+6lqKiIQ4cOsW3bNgBWrVoVd7tdunTBzFi/fn3zch07dmTgwIHcfffdzW0P95MD3HLLLYwZM4aBAwdy5plnpu6DSJOEQtvM2gP3A1OP0qbAzLq0fADFKalSRIJxxRVX0LVrV7p3787gwYPp27cvAEOGDGHWrFkMHz6ckpISLrnkEvbs2UO3bt146KGH+Pa3v01JSQkDBgxg+/btRCIRFi5cyKWXXsrFF19Mbm7uUbc7b948Zs6cSZ8+fVizZg0XXHBB87xHH32UF154gV69elFSUsLDDz/cPG/MmDHs3r2badPCuF95QuNpm9ldwF/c/X4z2w5c4+5vxLT5GTC7teU1nrZIemk87WNXXl7OlClT2Lp16xHdLcdLsuNpx/0i0swGABcCd8RpugBYGjOtGCiLtw0RkUz4zne+w/r161m+fHlGAvtYJHL2yGDgPKAy+kMVA8+a2U3u/l+HG7l7DVDTcsFQPgQR+WJq2U0Sirh92u4+z93PcPcu7t4FqAIubxnYIiJyfOgydhGRgCR9cU30aFtERDJAR9oiIgFRaIuIBEShLSIZN2TIENauXdvm/O3btzePF/JFp9AWEQmIRvkTOcHc9cpdvP3x22lZ97lfOpcfXfyjo7aZM2cO1dXVzWN9VFdX06NHD5YtW9Y8eFTseNfJeuaZZ5g1axYNDQ107tyZJUuWcM4551BRUcGkSZM4cOAADQ0NTJo0iZkzZ/LEE09w5513kpubS319Pffddx9Dhgw5pm1nmkJbRFJqwoQJfOMb3+BXv/oVkUiEVatWMXLkSAYOHNjmeNfJ+OCDDxg/fjzPP/88PXv25OGHH2bcuHG8/PLLPPDAA4wcOZJZs2YBTWNsA/z0pz/lwQcfZMCAATQ0NLB///6U/9zHi0Jb5AQT70g43b72ta9x/vnns27dOkaOHMnSpUu5++672xzvun///kmt/+WXX6akpISePXsCcNNNNzFt2jT27t3LN7/5TX74wx9y4MABhg4dytChQwG45JJLuO222xg9ejRXXnklvXqFO7q0+rRFJOUmTZrEsmXL2Lp1K3v27GHQoEHHNN51skaPHk1ZWRldu3Zl3rx5jB8/HoC7776bhx56iLy8PK677joeeuihlG73eFJoi0jKXXvttfzxj3/k17/+NZMmTcLM2hzvOln9+/fnT3/6E2+/3dRvv2zZMr7+9a/TqVMntm3bRlFREZMmTWL27Nm88sorAFRUVNC7d29uvfVWbrzxRjZv3pyyn/V4U/eIiKTcSSedxKhRo3jkkUeorKwEmsa7njZtGrNnz+aiiy46YrzrZHTu3JkVK1Zwww03UF9fT+fOnXn00UcBWLNmDStXriQvLw8za76J8B133NHcLVNQUBDkQFGHJTSe9jGvvOlGCJUaT1skvTSedriSHU9b3SMiIgFR94iIZI0pU6bw0ksvHTEtEonw6quvZqii7KPQFpGssXjx4kyXkPXUPSIiEhCFtohIQBTaIiIBSahP28z+AJwFNAL7gFvc/fV0FiYiIp+V6JH2RHcvcfevA/OB0jTWJCJfMPHG05Z/SOhI2933tHh7Ck1H3EcwswKgIGZy8bGXJiKSWQ0NDeTm5ma6jCMkfMqfmf0/4DLAgCtaaTIDmJ2iukTkGO2cO5e6t9Iznnb7886l6Mc/PmqbdIynXV9fz9VXX011dTWffvopF198MUuWLCEvLw+AX/ziF6xatYqcnBw6dOhAeXk5OTk5lJaWNl/KnpeXx9q1a3nrrbeYOXNm87nfmzZtan6/adMmpk+fTr9+/diyZQtz5szhk08+YeHChRw8eBCA+fPnM2zYMKDpasZbb72VnTt34u7MnDmTnj17ctNNN/HGG280119SUsKiRYsYOHBgEp926xIObXe/GcDMxgO/Aq6KabIAWBozrRgo+xz1iUhg0jGedm5uLqtWraKwsBB3Z+LEiZSWljJlyhSWLVvGk08+yYsvvkinTp2orq4mJyeHTZs2MXfuXMrLyykqKmLfvn1EIvEj780332TJkiUMGDAAaPqlM3bsWMyMiooKhg0bRlVVFfX19YwaNYqf//znXHfddc1tCwsL6dixI88//zyDBw+mrKyMnJyclAQ2HMPFNe6+wsweNLNCd69uMb0GqGnZ1sxSUKKIJCPekXC6pWM87cbGRubPn8/TTz9NQ0MDu3fv5qSTTgJg7dq1TJ06lU6dOgFQWFgIwFNPPcWECRMoKioCoGPHjgnV361bt+bABnjvvfcYO3YsO3bsoF27duzcuZOdO3dSXV1NfX19c2C33Pb06dN54IEHGDx4MPfffz/f//73E9p2IuJ+EWlmHc3szBbvRwAfRx8iIp+R6vG0V61aRXl5OWVlZWzdupVp06Yd81jckUiExsZ/fC0Xu57YcB87dizTpk3jzTff5LXXXiMSicTd9nXXXcdLL73Eli1b2LhxIzfccMMx1dqaRM4e6QD8zsy2mtnrwG3ACE/n8IAiErRUj6ddU1PDaaedRqdOndizZw+rVq1qnnfNNdewaNEi9u7dCzR1UQBcffXVLF++nF27dgGwb98+amtrOfvss3n//ffZvXs37s7q1avjbjs64h6lpaXU1dUB0KNHDyKRCL/73e+a2x7edrt27Zg8eTIjR45k3LhxzX8VpELc0Hb3Xe7e3917u3sfd7/E3V9LWQUicsI5PJ72ihUrmDBhAtA0nvbMmTPp06cPa9asSWo87QkTJrB3717OPfdcRowYwaBBg46YN2LECPr370+fPn0YNWoUjY2NDBkyhFmzZjF8+HBKSkq45JJL2LNnD2eccQY/+MEP6NevHwMHDuQrX/nKUbe9YMECvvWtb9G3b1/ef//95i6QSCTCE088weLFi+nduzclJSWsW7euebmbb76ZHTt2MHXq1GQ+urg0nrbICUDjaWefRx99lNWrV/PUU08dtV2y42lrlD8RkRS7/PLLee+993jyySdTvm6FtohkjRNlPO1nn302betWaItI1tB42vFplD+RE4RO6ArPsfybKbRFTgD5+flUV1cruAPi7lRXV5Ofn5/UcuoeETkBFBcXU1VVxYcffpjpUiQJ+fn5FBcnN66eQlvkBNCuXbvmC0DkxKbuERGRgCi0RUQCotAWEQmIQltEJCAKbRGRgCi0RUQCotAWEQmIQltEJCAKbRGRgCRyj8hCM1tnZhXRW4793sw6H4/iRETkSIkcaTvwS3fv4e69gfeAeektS0REWhN37BF3/xjY1GLSS8BnbnpmZgVAQczk5EZCERGRo0pqwCgzy6EpsFu7h84MYHYqihIRkdYlO8rfvcA+4L5W5i0AlsZMKwbKki9LRERak3Bom9l8oBswwt0bY+e7ew1QE7PM5y5QRET+IaHQNrO5QD/ganevS29JIiLSlrihbWbnA7OAd4AXo0fPle7+r2muTUREYiRy9sibgPo5RESygK6IFBEJiEJbRCQgCm0RkYAotEVEAqLQFhEJiEJbRCQgCm0RkYAotEVEAqLQFhEJiEJbRCQgCm0RkYAotEVEAqLQFhEJiEJbRCQgCm0RkYAotEVEAhI3tM1svplVmpmbWa/jUZSIiLQukSPtPwDfBP6c5lpERCSORG43Vg66s7qISDZI6G7siTCzAqAgZnJxqtYvIiIpDG1gBjA7hesTEZEYqQztBcDSmGnFQFkKtyEi8oWWstB29xqgpuU09YOLiKRWIqf83WNmVTQdNW8wszfTX5aIiLQmkbNHpgPTj0MtIiISh66IFBEJiEJbRCQgCm0RkYCk8pS/1Hq1FA5UA9EzUMxS/1pEJJ0unAy5qY3Z7A3tl5fAh29nugoRkWPXd8IXKLSnlIN79I2n6DVHvhYRSadI+9SvMuVrTJXcdpmuQEQk6+iLSBGRgCi0RUQCotAWEQmIQltEJCAKbRGRgCi0RUQCotAWEQmIQltEJCAKbRGRgCi0RUQCklBom1l3M/tvM3sn+twt3YWJiMhnJXqkvRi43927A/cDS9JXkoiItCXugFFm9mWgL3BpdNJq4D4z6+zuH7ZoVwAUxCxefKyF7Zw7l7q3NDSriISp/XnnUvTjH6d8vYmM8ncmsMPdGwDcvcHM/had/mGLdjOA2SmvUEREmqVyaNYFwNKYacVA2bGsLB2/oUREQpdIaP8V+KqZ5UaPsnOBM6LTm7l7DVDTcpqZbuslIpJKcb+IdPcPgNeBsdFJY4EtLfuzRUTk+Ei0e2QKsMzMfgrsBiakryQREWlLQqHt7m8D30hzLSIiEoeuiBQRCYhCW0QkIAptEZGApPI87dbkAlRVVaV5MyIiJ44WmZkbO8/cPW0bNrN/4RgvrhEREQa5e3nLCekO7fbARcDfgYYkFz98NeUgINsP1UOqFcKqN6RaIax6Q6oVwqr389aaC3wF2OzudS1npLV7JLqx8rgNW9Hiasoqd9+eqprSIaRaIax6Q6oVwqo3pFohrHpTVOt7rU3UF5EiIgFRaIuIBEShLSISkGwO7Rrg34kZOTBLhVQrhFVvSLVCWPWGVCuEVW/aak3r2SMiIpJa2XykLSIiMRTaIiIBUWiLiAQkK0PbzLqb2X+b2TvR526ZrqktZlZoZuvMrMLMtprZ782sc6brisfMZpuZm1mvTNdyNGaWb2aLzOzd6Of7YKZraouZXWNmW8zsdTP7k5ldm+maWjKz+WZWGfvvno37W2u1ZvO+1tZn22J+yva3rAxtYDFwv7t3B+4HlmS4nqNx4Jfu3sPde9N0FdO8DNd0VGbWF+gP/DnTtSTgl0At0D36+f5bhutplTVdArcCGO/ufYDxNN3tKZv2sT8A3+Sz/+7ZuL+1Vms272ttfbYp39+y6T8UAGb2ZaAvsDo6aTXQN1t+o8Zy94/dfVOLSS8B/5ShcuKKjgdzPzA107XEY2Ydabq13b959DQnd9+V2aqOqhE4Jfq6APi7uzdmsJ4juHu5ux9xQ+5s3d9aqzWb97XW6oX07G9ZF9rAmcAOd28AiD7/LTo9q0WPqqYCT2a6lqP4v8Cj2T52Q1RXoBqYbWavmtmm6MiRWSf6S+V64Akz+zNNR14h3Es1yP0tkH0N0rC/ZWNoh+xeYB9wX6YLaY2ZDQAuBB7IdC0JygXOBra4+4XAj4Dfm9nJmS3rs8wsAswCRrn7PwEjgDXRvxYk9bJ6X4P07W/ZGNp/Bb5qZrkA0eczotOzlpnNB7oB386mP4ljDAbOAyrNbDtNw0c+a2aXZbSqtv0FqCf6p7u7vwx8BHTPZFFt6AOc4e4vAESf99P0eWez4Pa3QPY1SNP+lnWh7e4fAK8DY6OTxtJ0pPVh5qo6OjObC/QDvhU79m02cfd57n6Gu3dx9y40jfN7ubv/V4ZLa5W7fwRsBC6FprMcgC8D2zJZVxuqgGIz6wFgZucBp9PG8JrZIrT9LZR9DdK3v2XlZexmdi6wDDgV2A1McPeKzFbVOjM7H3gDeAf4NDq50t3/NXNVJSb62/8ad38j07W0xczOBkqBQuAQ8BN3fzqzVbXOzMYBd9D0hSTAbHf/QwZLOoKZ3QNcCxTR9BdLtbufn437W2u10vSdQVbua219tjFttpOC/S0rQ1tERFqXdd0jIiLSNoW2iEhAFNoiIgFRaIuIBEShLSISEIW2iEhAFNoiIgH5/5HaYlwcw3p0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA2CpwwDdGm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ecbe024-9044-4e0c-afc5-1700e9f0903e"
      },
      "source": [
        "predictions = perceptron_keras.predict(X).argmax(axis=1)\n",
        "accuracy_score(y.argmax(axis=1), predictions)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEyG7Pvi7gpS",
        "outputId": "13f7871f-1e9f-4e43-f86b-1ceed2aed4d5"
      },
      "source": [
        "perceptron_keras.predict(X)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.],\n",
              "       ...,\n",
              "       [1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tLLusKmdGm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "ecaf1f75-6370-400f-b0a6-4d8fe3346a81"
      },
      "source": [
        "def get_y(x, w1, w2, bias):\n",
        "    '''\n",
        "    compute y value for specific x, given the weights and bias\n",
        "    (helper function for decision boundary)\n",
        "    '''\n",
        "    return ((-(x * w1) - bias) / w2)\n",
        "    \n",
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "pd.DataFrame({'x1': a, 'x2': b}).plot.scatter(x='x1', y='x2', c=['red']*half + ['blue']*half, ax=ax);\n",
        "\n",
        "(w1, w2), bias = perceptron_keras.get_weights()\n",
        "xmin, xmax = X[:,0].min() - 1, X[:,0].max() + 1\n",
        "ymin, ymax = X[:,1].min() - 1, X[:,1].max() + 1\n",
        "\n",
        "ax.plot([xmin, xmax], [get_y(xmin, w1, w2, bias)[1], get_y(xmax, w1, w2, bias)[1]], marker='o', color='green');\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EzG65qfdGm8"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56FkOJ1tdGm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68bcf5ee-80bc-4c2a-922f-4b0e483e5225"
      },
      "source": [
        "# input: a sequence  of 2 integers\n",
        "mlp_input = Input(shape=(2,), name='main_input')\n",
        "\n",
        "# add a hidden layer (16 neurons)\n",
        "mlp_hidden = Dense(16, activation='relu', name='hidden', kernel_initializer='glorot_uniform')(mlp_input)\n",
        "\n",
        "# add the output layer\n",
        "mlp_output = Dense(2, activation='softmax', name='output', kernel_initializer='glorot_uniform')(mlp_hidden)\n",
        "\n",
        "# the model is specified by connecting input and output\n",
        "mlp = Model(inputs=[mlp_input], outputs=[mlp_output])\n",
        "\n",
        "mlp.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "main_input (InputLayer)      [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "hidden (Dense)               (None, 16)                48        \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 2)                 34        \n",
            "=================================================================\n",
            "Total params: 82\n",
            "Trainable params: 82\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lFkGmrfDdGm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fa8619e-ca5f-422d-b85b-0037f18cb9ca"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "optimizer = optimizers.Adam(lr=0.001)\n",
        "\n",
        "mlp.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy']\n",
        "           )\n",
        "\n",
        "mlp_history = mlp.fit(X, y,\n",
        "                    epochs=50,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "125/125 [==============================] - 1s 3ms/step - loss: 1.1871 - accuracy: 0.4783 - val_loss: 0.9941 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8181 - val_loss: 0.7993 - val_accuracy: 0.3530\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.9532 - val_loss: 0.5496 - val_accuracy: 0.7830\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.2532 - accuracy: 0.9874 - val_loss: 0.3771 - val_accuracy: 0.9350\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9949 - val_loss: 0.2778 - val_accuracy: 0.9640\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9953 - val_loss: 0.2399 - val_accuracy: 0.9660\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9975 - val_loss: 0.1962 - val_accuracy: 0.9750\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9971 - val_loss: 0.1558 - val_accuracy: 0.9790\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9984 - val_loss: 0.1294 - val_accuracy: 0.9810\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 0.9968 - val_loss: 0.1090 - val_accuracy: 0.9840\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9979 - val_loss: 0.0933 - val_accuracy: 0.9850\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9977 - val_loss: 0.0639 - val_accuracy: 0.9920\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9986 - val_loss: 0.0505 - val_accuracy: 0.9960\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 0.9986 - val_loss: 0.0761 - val_accuracy: 0.9840\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9982 - val_loss: 0.0567 - val_accuracy: 0.9890\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9984 - val_loss: 0.0541 - val_accuracy: 0.9890\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9987 - val_loss: 0.0322 - val_accuracy: 0.9970\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9989 - val_loss: 0.0354 - val_accuracy: 0.9960\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9970 - val_loss: 0.0521 - val_accuracy: 0.9870\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9974 - val_loss: 0.0385 - val_accuracy: 0.9920\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9992 - val_loss: 0.0309 - val_accuracy: 0.9960\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9969 - val_loss: 0.0215 - val_accuracy: 0.9970\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9986 - val_loss: 0.0278 - val_accuracy: 0.9960\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 0.9985 - val_loss: 0.0223 - val_accuracy: 0.9970\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.0148 - val_accuracy: 0.9970\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 0.9990 - val_loss: 0.0311 - val_accuracy: 0.9920\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0261 - val_accuracy: 0.9940\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.0268 - val_accuracy: 0.9940\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.0172 - val_accuracy: 0.9970\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.0168 - val_accuracy: 0.9970\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.0276 - val_accuracy: 0.9920\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.0074 - val_accuracy: 0.9990\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.0077 - val_accuracy: 0.9990\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.0069 - val_accuracy: 0.9990\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0149 - val_accuracy: 0.9970\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.0167 - val_accuracy: 0.9970\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0066 - val_accuracy: 0.9990\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.0099 - val_accuracy: 0.9970\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9995 - val_loss: 0.0078 - val_accuracy: 0.9970\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0069 - val_accuracy: 0.9970\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9996 - val_loss: 0.0062 - val_accuracy: 0.9990\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0093 - val_accuracy: 0.9970\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.0157 - val_accuracy: 0.9970\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 0.0098 - val_accuracy: 0.9970\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0099 - val_accuracy: 0.9970\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0142 - val_accuracy: 0.9970\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0035 - val_accuracy: 0.9990\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.0083 - val_accuracy: 0.9970\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0137 - val_accuracy: 0.9970\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9981 - val_loss: 0.0068 - val_accuracy: 0.9970\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmbTZBgkdGnA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94ef7689-d6ef-4703-a00c-9c51bb1fedf2"
      },
      "source": [
        "mlp_history = pd.DataFrame(mlp_history.history)\n",
        "mlp_history\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.762037</td>\n",
              "      <td>0.58025</td>\n",
              "      <td>0.994142</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.415749</td>\n",
              "      <td>0.86325</td>\n",
              "      <td>0.799287</td>\n",
              "      <td>0.353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.320396</td>\n",
              "      <td>0.96825</td>\n",
              "      <td>0.549608</td>\n",
              "      <td>0.783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.233895</td>\n",
              "      <td>0.98975</td>\n",
              "      <td>0.377074</td>\n",
              "      <td>0.935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.167024</td>\n",
              "      <td>0.99450</td>\n",
              "      <td>0.277783</td>\n",
              "      <td>0.964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.121428</td>\n",
              "      <td>0.99600</td>\n",
              "      <td>0.239883</td>\n",
              "      <td>0.966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.090571</td>\n",
              "      <td>0.99700</td>\n",
              "      <td>0.196212</td>\n",
              "      <td>0.975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.069791</td>\n",
              "      <td>0.99750</td>\n",
              "      <td>0.155845</td>\n",
              "      <td>0.979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.055720</td>\n",
              "      <td>0.99750</td>\n",
              "      <td>0.129385</td>\n",
              "      <td>0.981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.045515</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>0.108967</td>\n",
              "      <td>0.984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.038110</td>\n",
              "      <td>0.99825</td>\n",
              "      <td>0.093322</td>\n",
              "      <td>0.985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.032606</td>\n",
              "      <td>0.99850</td>\n",
              "      <td>0.063933</td>\n",
              "      <td>0.992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.028188</td>\n",
              "      <td>0.99850</td>\n",
              "      <td>0.050476</td>\n",
              "      <td>0.996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.024759</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>0.076102</td>\n",
              "      <td>0.984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.022084</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>0.056694</td>\n",
              "      <td>0.989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.019647</td>\n",
              "      <td>0.99825</td>\n",
              "      <td>0.054132</td>\n",
              "      <td>0.989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.017740</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>0.032219</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.016189</td>\n",
              "      <td>0.99825</td>\n",
              "      <td>0.035423</td>\n",
              "      <td>0.996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.014970</td>\n",
              "      <td>0.99825</td>\n",
              "      <td>0.052071</td>\n",
              "      <td>0.987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.013749</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>0.038538</td>\n",
              "      <td>0.992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.012677</td>\n",
              "      <td>0.99825</td>\n",
              "      <td>0.030926</td>\n",
              "      <td>0.996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.011864</td>\n",
              "      <td>0.99800</td>\n",
              "      <td>0.021524</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.010894</td>\n",
              "      <td>0.99875</td>\n",
              "      <td>0.027790</td>\n",
              "      <td>0.996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.010218</td>\n",
              "      <td>0.99825</td>\n",
              "      <td>0.022278</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.009811</td>\n",
              "      <td>0.99850</td>\n",
              "      <td>0.014784</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.009142</td>\n",
              "      <td>0.99875</td>\n",
              "      <td>0.031095</td>\n",
              "      <td>0.992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.008855</td>\n",
              "      <td>0.99850</td>\n",
              "      <td>0.026070</td>\n",
              "      <td>0.994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.008484</td>\n",
              "      <td>0.99825</td>\n",
              "      <td>0.026842</td>\n",
              "      <td>0.994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.008015</td>\n",
              "      <td>0.99825</td>\n",
              "      <td>0.017174</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.007462</td>\n",
              "      <td>0.99900</td>\n",
              "      <td>0.016773</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.007112</td>\n",
              "      <td>0.99900</td>\n",
              "      <td>0.027553</td>\n",
              "      <td>0.992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.007002</td>\n",
              "      <td>0.99850</td>\n",
              "      <td>0.007389</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.006382</td>\n",
              "      <td>0.99900</td>\n",
              "      <td>0.007706</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.006524</td>\n",
              "      <td>0.99875</td>\n",
              "      <td>0.006935</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.006216</td>\n",
              "      <td>0.99875</td>\n",
              "      <td>0.014893</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.005760</td>\n",
              "      <td>0.99875</td>\n",
              "      <td>0.016652</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.005645</td>\n",
              "      <td>0.99900</td>\n",
              "      <td>0.006561</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.005733</td>\n",
              "      <td>0.99875</td>\n",
              "      <td>0.009933</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.005345</td>\n",
              "      <td>0.99925</td>\n",
              "      <td>0.007771</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.005198</td>\n",
              "      <td>0.99900</td>\n",
              "      <td>0.006923</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.004805</td>\n",
              "      <td>0.99925</td>\n",
              "      <td>0.006187</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.004982</td>\n",
              "      <td>0.99875</td>\n",
              "      <td>0.009290</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.004652</td>\n",
              "      <td>0.99925</td>\n",
              "      <td>0.015669</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.004750</td>\n",
              "      <td>0.99900</td>\n",
              "      <td>0.009770</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.004404</td>\n",
              "      <td>0.99900</td>\n",
              "      <td>0.009851</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.004215</td>\n",
              "      <td>0.99925</td>\n",
              "      <td>0.014179</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.003869</td>\n",
              "      <td>0.99900</td>\n",
              "      <td>0.003536</td>\n",
              "      <td>0.999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.004085</td>\n",
              "      <td>0.99900</td>\n",
              "      <td>0.008277</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.003963</td>\n",
              "      <td>0.99900</td>\n",
              "      <td>0.013679</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.003948</td>\n",
              "      <td>0.99875</td>\n",
              "      <td>0.006833</td>\n",
              "      <td>0.997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy\n",
              "0   0.762037   0.58025  0.994142         0.000\n",
              "1   0.415749   0.86325  0.799287         0.353\n",
              "2   0.320396   0.96825  0.549608         0.783\n",
              "3   0.233895   0.98975  0.377074         0.935\n",
              "4   0.167024   0.99450  0.277783         0.964\n",
              "5   0.121428   0.99600  0.239883         0.966\n",
              "6   0.090571   0.99700  0.196212         0.975\n",
              "7   0.069791   0.99750  0.155845         0.979\n",
              "8   0.055720   0.99750  0.129385         0.981\n",
              "9   0.045515   0.99800  0.108967         0.984\n",
              "10  0.038110   0.99825  0.093322         0.985\n",
              "11  0.032606   0.99850  0.063933         0.992\n",
              "12  0.028188   0.99850  0.050476         0.996\n",
              "13  0.024759   0.99800  0.076102         0.984\n",
              "14  0.022084   0.99800  0.056694         0.989\n",
              "15  0.019647   0.99825  0.054132         0.989\n",
              "16  0.017740   0.99800  0.032219         0.997\n",
              "17  0.016189   0.99825  0.035423         0.996\n",
              "18  0.014970   0.99825  0.052071         0.987\n",
              "19  0.013749   0.99800  0.038538         0.992\n",
              "20  0.012677   0.99825  0.030926         0.996\n",
              "21  0.011864   0.99800  0.021524         0.997\n",
              "22  0.010894   0.99875  0.027790         0.996\n",
              "23  0.010218   0.99825  0.022278         0.997\n",
              "24  0.009811   0.99850  0.014784         0.997\n",
              "25  0.009142   0.99875  0.031095         0.992\n",
              "26  0.008855   0.99850  0.026070         0.994\n",
              "27  0.008484   0.99825  0.026842         0.994\n",
              "28  0.008015   0.99825  0.017174         0.997\n",
              "29  0.007462   0.99900  0.016773         0.997\n",
              "30  0.007112   0.99900  0.027553         0.992\n",
              "31  0.007002   0.99850  0.007389         0.999\n",
              "32  0.006382   0.99900  0.007706         0.999\n",
              "33  0.006524   0.99875  0.006935         0.999\n",
              "34  0.006216   0.99875  0.014893         0.997\n",
              "35  0.005760   0.99875  0.016652         0.997\n",
              "36  0.005645   0.99900  0.006561         0.999\n",
              "37  0.005733   0.99875  0.009933         0.997\n",
              "38  0.005345   0.99925  0.007771         0.997\n",
              "39  0.005198   0.99900  0.006923         0.997\n",
              "40  0.004805   0.99925  0.006187         0.999\n",
              "41  0.004982   0.99875  0.009290         0.997\n",
              "42  0.004652   0.99925  0.015669         0.997\n",
              "43  0.004750   0.99900  0.009770         0.997\n",
              "44  0.004404   0.99900  0.009851         0.997\n",
              "45  0.004215   0.99925  0.014179         0.997\n",
              "46  0.003869   0.99900  0.003536         0.999\n",
              "47  0.004085   0.99900  0.008277         0.997\n",
              "48  0.003963   0.99900  0.013679         0.997\n",
              "49  0.003948   0.99875  0.006833         0.997"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXee_GBNgkCA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "4480919f-5227-471d-82b8-3a8432c7a971"
      },
      "source": [
        "mlp_history['accuracy'.split()].plot()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f682d47e3d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZc1B5dLg1JE"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Take couple of minutes and try to play with the number of layers and the number of parameters in the layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQFsa0hW9WRf"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRQSCfdaLAtF"
      },
      "source": [
        "<a name=\"kaggle\"></a>\n",
        "# Kaggle Challenge Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbeKfwkVLAtG"
      },
      "source": [
        ">The Otto Group is one of the world’s biggest e-commerce companies, A consistent analysis of the performance of products is crucial. However, due to diverse global infrastructure, many identical products get classified differently.\n",
        "For this competition, we have provided a dataset with 93 features for more than 200,000 products. The objective is to build a predictive model which is able to distinguish between our main product categories. \n",
        "Each row corresponds to a single product. There are a total of 93 numerical features, which represent counts of different events. All features have been obfuscated and will not be defined any further.\n",
        "\n",
        "https://www.kaggle.com/c/otto-group-product-classification-challenge/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffeZ8QrxLAtK"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdAVJQYmMKtt"
      },
      "source": [
        "### Utility functions\n",
        "\n",
        "Utility functions to load Kaggle Otto Group Challenge Data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0GV97-fMI4B"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "def load_data(path, train=True):\n",
        "    \"\"\"Load data from a CSV File\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    path: str\n",
        "        The path to the CSV file\n",
        "        \n",
        "    train: bool (default True)\n",
        "        Decide whether or not data are *training data*.\n",
        "        If True, some random shuffling is applied.\n",
        "        \n",
        "    Return\n",
        "    ------\n",
        "    X: numpy.ndarray \n",
        "        The data as a multi dimensional array of floats\n",
        "    ids: numpy.ndarray\n",
        "        A vector of ids for each sample\n",
        "    \"\"\"\n",
        "    text = pd.read_csv(path, encoding = \"ISO-8859-2\")\n",
        "    df = pd.read_csv(path)\n",
        "    X = df.values.copy()\n",
        "    if train:\n",
        "        np.random.shuffle(X)  \n",
        "        X, labels = X[:, 1:-1].astype(np.float32), X[:, -1]\n",
        "        return X, labels\n",
        "    else:\n",
        "        X, ids = X[:, 1:].astype(np.float32), X[:, 0].astype(str)\n",
        "        return X, ids\n",
        "        \n",
        "        \n",
        "def preprocess_data(X, scaler=None):\n",
        "    \"\"\"Preprocess input data by standardise features \n",
        "    by removing the mean and scaling to unit variance\"\"\"\n",
        "    if not scaler:\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X)\n",
        "    X = scaler.transform(X)\n",
        "    return X, scaler\n",
        "\n",
        "\n",
        "def preprocess_labels(labels, encoder=None, categorical=True):\n",
        "    \"\"\"Encode labels with values among 0 and `n-classes-1`\"\"\"\n",
        "    if not encoder:\n",
        "        encoder = LabelEncoder()\n",
        "        encoder.fit(labels)\n",
        "    y = encoder.transform(labels).astype(np.int32)\n",
        "    if categorical:\n",
        "        y = np_utils.to_categorical(y)\n",
        "    return y, encoder"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaGr3p-HmvNU"
      },
      "source": [
        "## Import data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcwhGx_rLAtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6516f70b-d003-42ce-f204-cd165e3a21d2"
      },
      "source": [
        "url_train = 'https://raw.githubusercontent.com/leriomaggio/deep-learning-keras-tensorflow/master/data/kaggle_ottogroup/train.csv'\n",
        "url_test = 'https://raw.githubusercontent.com/leriomaggio/deep-learning-keras-tensorflow/master/data/kaggle_ottogroup/test.csv'\n",
        "X_train, labels = load_data(url_train, train=True)\n",
        "\n",
        "print(\"Training set data\")\n",
        "print(X_train)\n",
        "\n",
        "print(\"Training set labels\")\n",
        "print(labels)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set data\n",
            "[[0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 1. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 3. 0.]\n",
            " [0. 0. 0. ... 0. 1. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "Training set labels\n",
            "['Class_8' 'Class_2' 'Class_4' ... 'Class_6' 'Class_3' 'Class_2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHG7PflKmzeL"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4huHaAtLAta",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b081e753-daa6-49aa-c385-288aa050081c"
      },
      "source": [
        "X_train, labels = load_data(url_train, train=True)\n",
        "X_train, scaler = preprocess_data(X_train)\n",
        "Y_train, encoder = preprocess_labels(labels)\n",
        "\n",
        "X_test, ids = load_data(url_test, train=False)\n",
        "X_test, _ = preprocess_data(X_test, scaler)\n",
        "\n",
        "nb_classes = Y_train.shape[1]\n",
        "print(nb_classes, 'classes')\n",
        "\n",
        "dims = X_train.shape[1]\n",
        "print(dims, 'dims')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 classes\n",
            "93 dims\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl6vFpY4LAtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d1fd6e-613c-4351-d25f-84b22061144f"
      },
      "source": [
        "help(preprocess_data)\n",
        "help(preprocess_labels)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function preprocess_data in module __main__:\n",
            "\n",
            "preprocess_data(X, scaler=None)\n",
            "    Preprocess input data by standardise features \n",
            "    by removing the mean and scaling to unit variance\n",
            "\n",
            "Help on function preprocess_labels in module __main__:\n",
            "\n",
            "preprocess_labels(labels, encoder=None, categorical=True)\n",
            "    Encode labels with values among 0 and `n-classes-1`\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIQdg3xYLAtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92cafb1d-533a-4c16-e626-9b7b25c505ad"
      },
      "source": [
        "np.unique(labels)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
              "       'Class_7', 'Class_8', 'Class_9'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr8D9bzfLAty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a3bc775-e3aa-4f11-82e5-de5b2b1b19bf"
      },
      "source": [
        "Y_train  # one-hot encoding"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFfYHt-11uj2",
        "outputId": "acfd9378-a8fb-4a7a-a438-3345b541ef79"
      },
      "source": [
        "Y_train[1]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcLqsyXhLAt5"
      },
      "source": [
        "# Using Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yt1I627LAt6"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y0mXasYh6Gl"
      },
      "source": [
        "### Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTywtg5MGT0i",
        "outputId": "905eda6c-5c2d-49a9-f6b5-fcfd0c7f6840"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(61878, 93)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsSNGNdPLAt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea3154e-405a-4909-ddf0-73918afbe40e"
      },
      "source": [
        "dims = X_train.shape[1]\n",
        "print(dims, 'dims')\n",
        "print(\"Building model...\")\n",
        "\n",
        "nb_classes = Y_train.shape[1]\n",
        "print(nb_classes, 'classes')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(nb_classes, input_shape=(dims,), activation='sigmoid'))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
        "model.fit(X_train, Y_train)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93 dims\n",
            "Building model...\n",
            "9 classes\n",
            "1934/1934 [==============================] - 2s 854us/step - loss: 2.0804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6827355390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJrsIfW_h22F"
      },
      "source": [
        "### Multi-layer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfDN7z7Xh2jn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d66e406-444f-4797-f4ba-450a36c471cd"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(100, input_shape=(dims,)))\n",
        "model.add(Dense(nb_classes, activation='softmax'))\n",
        "#model.add(Activation('softmax'))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
        "model.summary()\n",
        "\n",
        "model.fit(X_train, Y_train, epochs=20, \n",
        "          batch_size=128, verbose=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 100)               9400      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 9)                 909       \n",
            "=================================================================\n",
            "Total params: 10,309\n",
            "Trainable params: 10,309\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 1.5327\n",
            "Epoch 2/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.8206\n",
            "Epoch 3/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.7527\n",
            "Epoch 4/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.7285\n",
            "Epoch 5/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.7048\n",
            "Epoch 6/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6931\n",
            "Epoch 7/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6854\n",
            "Epoch 8/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6728\n",
            "Epoch 9/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6641\n",
            "Epoch 10/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6630\n",
            "Epoch 11/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6661\n",
            "Epoch 12/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6588\n",
            "Epoch 13/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6558\n",
            "Epoch 14/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6499\n",
            "Epoch 15/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6577\n",
            "Epoch 16/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6542\n",
            "Epoch 17/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6540\n",
            "Epoch 18/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6519\n",
            "Epoch 19/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6466\n",
            "Epoch 20/20\n",
            "484/484 [==============================] - 1s 1ms/step - loss: 0.6554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f682730d950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSKkN1j8fyRi"
      },
      "source": [
        "# Exercise\n",
        "\n",
        "Try several configuration of the neural network considering also the use of the Dropout regularization. Evaluate model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BHLQtk82_tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5eaf8a7-c99d-4a83-bb78-0232eea3925f"
      },
      "source": [
        "url_train = 'https://raw.githubusercontent.com/leriomaggio/deep-learning-keras-tensorflow/master/data/kaggle_ottogroup/train.csv'\n",
        "url_test = 'https://raw.githubusercontent.com/leriomaggio/deep-learning-keras-tensorflow/master/data/kaggle_ottogroup/test.csv'\n",
        "\n",
        "X_train, labels = load_data(url_train, train=True)\n",
        "X_train, scaler = preprocess_data(X_train)\n",
        "Y_train, encoder = preprocess_labels(labels)\n",
        "\n",
        "X_test, ids = load_data(url_test, train=False)\n",
        "X_test, _ = preprocess_data(X_test, scaler)\n",
        "\n",
        "nb_classes = Y_train.shape[1]\n",
        "print(nb_classes, 'classes')\n",
        "\n",
        "dims = X_train.shape[1]\n",
        "print(dims, 'dims')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 classes\n",
            "93 dims\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kKzD5tr95nC",
        "outputId": "0129e1fd-9545-43b3-f021-dec0dd6a17bb"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(dims,), activation='relu'))\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(128, activation='relu'))\n",
        "#model.add(Dropout(0.5)) \n",
        "model.add(Dense(nb_classes, activation='softmax')) \n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=20, \n",
        "          batch_size=128, verbose=True, validation_split = 0.1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_15 (Dense)             (None, 512)               48128     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 9)                 1161      \n",
            "=================================================================\n",
            "Total params: 114,953\n",
            "Trainable params: 114,953\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "436/436 [==============================] - 3s 6ms/step - loss: 0.8626 - accuracy: 0.7010 - val_loss: 0.5640 - val_accuracy: 0.7835\n",
            "Epoch 2/20\n",
            "436/436 [==============================] - 2s 6ms/step - loss: 0.5622 - accuracy: 0.7809 - val_loss: 0.5395 - val_accuracy: 0.7896\n",
            "Epoch 3/20\n",
            "436/436 [==============================] - 3s 6ms/step - loss: 0.5223 - accuracy: 0.7931 - val_loss: 0.5149 - val_accuracy: 0.8006\n",
            "Epoch 4/20\n",
            "436/436 [==============================] - 2s 6ms/step - loss: 0.5014 - accuracy: 0.8017 - val_loss: 0.5158 - val_accuracy: 0.7977\n",
            "Epoch 5/20\n",
            "436/436 [==============================] - 3s 6ms/step - loss: 0.4821 - accuracy: 0.8104 - val_loss: 0.5020 - val_accuracy: 0.8067\n",
            "Epoch 6/20\n",
            "436/436 [==============================] - 2s 6ms/step - loss: 0.4721 - accuracy: 0.8121 - val_loss: 0.4952 - val_accuracy: 0.8111\n",
            "Epoch 7/20\n",
            "436/436 [==============================] - 2s 6ms/step - loss: 0.4476 - accuracy: 0.8192 - val_loss: 0.4898 - val_accuracy: 0.8041\n",
            "Epoch 8/20\n",
            "436/436 [==============================] - 2s 5ms/step - loss: 0.4354 - accuracy: 0.8244 - val_loss: 0.4949 - val_accuracy: 0.8080\n",
            "Epoch 9/20\n",
            "436/436 [==============================] - 2s 5ms/step - loss: 0.4346 - accuracy: 0.8249 - val_loss: 0.4910 - val_accuracy: 0.8119\n",
            "Epoch 10/20\n",
            "436/436 [==============================] - 2s 5ms/step - loss: 0.4236 - accuracy: 0.8306 - val_loss: 0.4880 - val_accuracy: 0.8087\n",
            "Epoch 11/20\n",
            "436/436 [==============================] - 2s 5ms/step - loss: 0.4084 - accuracy: 0.8362 - val_loss: 0.4917 - val_accuracy: 0.8172\n",
            "Epoch 12/20\n",
            "436/436 [==============================] - 2s 5ms/step - loss: 0.4042 - accuracy: 0.8371 - val_loss: 0.4923 - val_accuracy: 0.8135\n",
            "Epoch 13/20\n",
            "436/436 [==============================] - 2s 5ms/step - loss: 0.3846 - accuracy: 0.8453 - val_loss: 0.4876 - val_accuracy: 0.8151\n",
            "Epoch 14/20\n",
            "436/436 [==============================] - 2s 5ms/step - loss: 0.3844 - accuracy: 0.8443 - val_loss: 0.4857 - val_accuracy: 0.8172\n",
            "Epoch 15/20\n",
            "436/436 [==============================] - 2s 6ms/step - loss: 0.3745 - accuracy: 0.8469 - val_loss: 0.4947 - val_accuracy: 0.8169\n",
            "Epoch 16/20\n",
            "436/436 [==============================] - 2s 6ms/step - loss: 0.3638 - accuracy: 0.8515 - val_loss: 0.4941 - val_accuracy: 0.8161\n",
            "Epoch 17/20\n",
            "436/436 [==============================] - 2s 5ms/step - loss: 0.3552 - accuracy: 0.8585 - val_loss: 0.4939 - val_accuracy: 0.8138\n",
            "Epoch 18/20\n",
            "436/436 [==============================] - 2s 6ms/step - loss: 0.3515 - accuracy: 0.8568 - val_loss: 0.5037 - val_accuracy: 0.8159\n",
            "Epoch 19/20\n",
            "436/436 [==============================] - 2s 6ms/step - loss: 0.3506 - accuracy: 0.8573 - val_loss: 0.5001 - val_accuracy: 0.8188\n",
            "Epoch 20/20\n",
            "436/436 [==============================] - 2s 5ms/step - loss: 0.3440 - accuracy: 0.8632 - val_loss: 0.5047 - val_accuracy: 0.8153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_POdxIDV9iM",
        "outputId": "faeb68ea-5eaa-415f-8374-5843468fc7cd"
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, Y_train,\n",
        "                       batch_size=128, verbose=1)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "484/484 [==============================] - 1s 2ms/step - loss: 0.3086 - accuracy: 0.8784\n",
            "Test loss: 0.30862823128700256\n",
            "Test accuracy: 0.8783735632896423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gydV0DMSiHe",
        "outputId": "a6fcff95-ae2e-43aa-d092-7582c5d3b3e5"
      },
      "source": [
        "model.predict_classes(X_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 7, 5, ..., 1, 3, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQyhcer4dGnC"
      },
      "source": [
        "# Further reading\n",
        "\n",
        "- http://u.cs.biu.ac.il/~yogo/nnlp.pdf (Chapters 1-4)\n",
        "- https://github.com/nyu-dl/NLP_DL_Lecture_Note/blob/master/lecture_note.pdf (Chapters 3, 4)\n",
        "- https://www.coursera.org/learn/machine-learning (Weeks 4, 5)\n",
        "- http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/"
      ]
    }
  ]
}