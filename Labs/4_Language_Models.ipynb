{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "4_Language_Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8BGYonOGP0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58baab8-f3e9-425d-9d99-a994b3ea599d"
      },
      "source": [
        "! pip install wget\n",
        "import wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=0db67338cb735214ccddcb473b04a922373557110268b732e3e65de3750a8003\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJjCXG1IGPdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68d5d223-24fd-4516-dbcd-7a01435660a1"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/dirkhovy/NLPclass/master/data/moby_dick.txt'\n",
        "wget.download(url, 'moby_dick.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'moby_dick.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8EH2_u-Fugs"
      },
      "source": [
        "# Language Models\n",
        "\n",
        "Let's start with a simple, Laplace-smoothed trigram model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U00eZfVGFugw"
      },
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "smoothing = 0.001 # a factor helps the model to deal with unknown words\n",
        "START = '_***_'\n",
        "STOP = '_STOP_'\n",
        "\n",
        "# map from (u, v) to w = (w|u,v)\n",
        "# a dict that counts how many times we see a trigram, we will count from 0.001 not 0\n",
        "counts = defaultdict(lambda: defaultdict(lambda: smoothing))\n",
        "\n",
        "# fit data on corpus\n",
        "corpus = [line.strip().split() for line in open('moby_dick.txt')]\n",
        "\n",
        "# collect counts for MLE\n",
        "for sentence in corpus:\n",
        "    # include special tokens for start and the end of sentence\n",
        "    tokens = [START, START] + sentence + [STOP]\n",
        "    for u, v, w in nltk.ngrams(tokens, 3):\n",
        "        counts[(u, v)][w] += 1\n",
        "\n",
        "def logP(u, v, w): \n",
        "    \"\"\"\n",
        "    compute the log probability of a trigram\n",
        "    (u,v,w) => P(w|u,v) = c(u,v,w) / SUM(c(u,v,*))\n",
        "    \"\"\"\n",
        "    return np.log(counts[(u, v)][w]) - np.log(sum(counts[(u, v)].values()))\n",
        "\n",
        "def sentence_logP(S):\n",
        "    \"\"\"\n",
        "    score a sentence in log likelihood with chain rule\n",
        "    S: list(str)\n",
        "    \"\"\"\n",
        "    tokens = [START, START] + S + [STOP]\n",
        "    return sum([logP(u, v, w) for u, v, w in nltk.ngrams(tokens, 3)])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF42v_H7ufxb",
        "outputId": "abcaa303-0532-4e10-c095-30d0854a75f9"
      },
      "source": [
        "counts[('because','he')]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>.<locals>.<lambda>>,\n",
              "            {'always': 1.001,\n",
              "             'could': 1.001,\n",
              "             'had': 2.001,\n",
              "             'happens': 1.001,\n",
              "             'is': 1.001,\n",
              "             'knows': 1.001,\n",
              "             'seemed': 1.001,\n",
              "             'treated': 1.001,\n",
              "             'tucks': 1.001,\n",
              "             'wanted': 1.001,\n",
              "             'was': 2.001})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoFO0lO1FuhA"
      },
      "source": [
        "We can now score arbitrary sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwJBkbQrFuhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80cac5bf-1c29-4719-d872-f0aaa4fd3f0c"
      },
      "source": [
        "sentence_logP('Captain Ahab is a man .'.split())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-27.92672048112014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybbofi_lkgFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71be1a50-df42-4200-9ea0-46118fbca94c"
      },
      "source": [
        "counts[('you','are')]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>.<locals>.<lambda>>,\n",
              "            {',': 1.001,\n",
              "             '.': 1.001,\n",
              "             'all': 1.001,\n",
              "             'an': 1.001,\n",
              "             'but': 1.001,\n",
              "             'close': 1.001,\n",
              "             'dead': 1.001,\n",
              "             'determined': 1.001,\n",
              "             'eating': 1.001,\n",
              "             'experienced': 1.001,\n",
              "             'goin': 1.001,\n",
              "             'heavy': 1.001,\n",
              "             'in': 3.001,\n",
              "             'just': 1.001,\n",
              "             'mistaken': 1.001,\n",
              "             'now': 3.001,\n",
              "             'only': 1.001,\n",
              "             'pitched': 1.001,\n",
              "             'quick': 1.001,\n",
              "             'skylarking': 1.001,\n",
              "             'speaking': 1.001,\n",
              "             'struck': 1.001,\n",
              "             'telling': 1.001,\n",
              "             'that': 1.001,\n",
              "             'the': 1.001})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqSc6ksAipHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c147dc-ec39-4ab0-9467-b8b0fcd69c5e"
      },
      "source": [
        "sum(counts[('you','are')].values())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29.02500000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz04HP-vFuh8"
      },
      "source": [
        "## Activity\n",
        "Implement the perplexity measure for a given corpus, and try it with two LM with different smoothing parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIPDCI6eFuh_"
      },
      "source": [
        "$$perplexity = 2^{-\\sum_{x \\in X} p(x) \\log p(x)}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTSRyIN4FuiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b72a6e-2d9e-4e51-9fc6-834f157f2a1d"
      },
      "source": [
        "def get_perplexity(corpus):\n",
        "    \"\"\"\n",
        "    perplexity = 2^-entropy(X)\n",
        "    entropy = -sum(p(x) *log(p(x)))\n",
        "    \"\"\"\n",
        "    entropy = 0.0\n",
        "    for sentence in corpus:\n",
        "        sentence_log_prob = sentence_logP(sentence)\n",
        "        sentence_entropy = np.exp(sentence_log_prob) * sentence_log_prob\n",
        "        entropy += sentence_entropy\n",
        "        \n",
        "    perplexity = 2 ** -entropy\n",
        "    return perplexity\n",
        "\n",
        "print(get_perplexity(corpus))\n",
        "#4.12 means the model will choose 4 words !!!   , when inferring a new word "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.118431257864399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGfhZxlhFuiL"
      },
      "source": [
        "## Generation\n",
        "\n",
        "We can re-use the counts to generate language:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL9kdmiEFuiN"
      },
      "source": [
        "def generate():\n",
        "    result = [START, START]\n",
        "    next_word = sample_next_word(result[-2], result[-1])\n",
        "    result.append(next_word)\n",
        "    while next_word != STOP:\n",
        "        next_word = sample_next_word(result[-2], result[-1])\n",
        "        result.append(next_word)\n",
        "    \n",
        "    return ' '.join(result[2:-1])\n",
        "\n",
        "def sample_next_word(u, v):\n",
        "    \"\"\"\n",
        "    sample a word w based on the history (u, v) --> the length of history is 2\n",
        "    \"\"\"\n",
        "    # separate word and their counts into separate variables\n",
        "    keys, values = zip(*counts[(u, v)].items())\n",
        "    \n",
        "    # normalize the counts into a probability distribution\n",
        "    values = np.array(values)\n",
        "    values /= values.sum() # create probability distro\n",
        "     \n",
        "    # this is the meat of the function\n",
        "    sample = np.random.multinomial(1, values) # pick one position\n",
        "    \n",
        "    return keys[np.argmax(sample)]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG51FZMWylr5",
        "outputId": "7ef19509-a405-497b-dc13-0fdabb747624"
      },
      "source": [
        "keys , values = zip(*counts[(START,START)].items())\r\n",
        "#keys, values #these are the possible start words with their counts\r\n",
        "keys , values = zip(*counts[('you','are')].items())\r\n",
        "values = np.array(values)\r\n",
        "values /= values.sum()\r\n",
        "values # the probability distribution for the keys"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10339363, 0.03448751, 0.03448751, 0.03448751, 0.03448751,\n",
              "       0.03448751, 0.03448751, 0.03448751, 0.03448751, 0.03448751,\n",
              "       0.03448751, 0.03448751, 0.10339363, 0.03448751, 0.03448751,\n",
              "       0.03448751, 0.03448751, 0.03448751, 0.03448751, 0.03448751,\n",
              "       0.03448751, 0.03448751, 0.03448751, 0.03448751, 0.03448751])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGPhqPGZz-UV",
        "outputId": "93d9f47a-a5a1-4207-9896-f4277cf10364"
      },
      "source": [
        "sample = np.random.multinomial(1, values) \r\n",
        "sample"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EO1OmOS-z-Wc",
        "outputId": "c9d3af17-8c3d-4b13-d1e5-28adf0b4774b"
      },
      "source": [
        "keys[np.argmax(sample)]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'an'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_atwtcfyemb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "MsqbTApXFuiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de89fe8-cc49-47ac-fe5a-9cff9bbf5b89"
      },
      "source": [
        "for i in range(50):\n",
        "    keys, values = zip(*counts[('you','are')].items())\n",
        "    values = np.array(values)\n",
        "    values /= values.sum()\n",
        "    sample = np.random.multinomial(1, values)\n",
        "    print(keys[np.argmax(sample)])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in\n",
            "in\n",
            "now\n",
            "telling\n",
            ".\n",
            "in\n",
            "eating\n",
            "but\n",
            ".\n",
            "experienced\n",
            "pitched\n",
            "now\n",
            "pitched\n",
            "mistaken\n",
            "quick\n",
            "dead\n",
            "but\n",
            "only\n",
            "mistaken\n",
            "goin\n",
            "dead\n",
            "just\n",
            "close\n",
            "that\n",
            "close\n",
            "close\n",
            "close\n",
            "that\n",
            "struck\n",
            "pitched\n",
            "now\n",
            "telling\n",
            "heavy\n",
            "the\n",
            "experienced\n",
            "quick\n",
            "only\n",
            "just\n",
            "telling\n",
            "close\n",
            "pitched\n",
            "mistaken\n",
            ",\n",
            "now\n",
            "goin\n",
            "goin\n",
            "now\n",
            "determined\n",
            "but\n",
            "just\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9glS5aGFFuiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235d348b-86aa-4380-cfd8-a3abd362e497"
      },
      "source": [
        "sample_next_word('as', 'a'), counts[('as', 'a')]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('passenger',\n",
              " defaultdict(<function __main__.<lambda>.<locals>.<lambda>>,\n",
              "             {'Commodore': 1.001,\n",
              "              'Dish': 1.001,\n",
              "              'Latin': 1.001,\n",
              "              'Roman': 1.001,\n",
              "              'backwoodsman': 1.001,\n",
              "              'bat': 1.001,\n",
              "              'birch': 1.001,\n",
              "              'body': 2.001,\n",
              "              'candidate': 1.001,\n",
              "              'cat': 1.001,\n",
              "              'civilized': 1.001,\n",
              "              'clam': 1.001,\n",
              "              'clock': 1.001,\n",
              "              'coffin': 1.001,\n",
              "              'conceited': 1.001,\n",
              "              'cook': 1.001,\n",
              "              'corpse': 1.001,\n",
              "              'country': 1.001,\n",
              "              'cricket': 1.001,\n",
              "              'crucible': 1.001,\n",
              "              'dead': 1.001,\n",
              "              'dinnerless': 1.001,\n",
              "              'dragon': 1.001,\n",
              "              'drawing': 1.001,\n",
              "              'dromedary': 1.001,\n",
              "              'fin': 1.001,\n",
              "              'flavorish': 1.001,\n",
              "              'fly': 1.001,\n",
              "              'foreshadowing': 1.001,\n",
              "              'frigate': 1.001,\n",
              "              'general': 6.0009999999999994,\n",
              "              'geologist': 1.001,\n",
              "              'giraffe': 1.001,\n",
              "              'god': 1.001,\n",
              "              'golden': 1.001,\n",
              "              'green': 1.001,\n",
              "              'harpoon': 1.001,\n",
              "              'harpooneer': 1.001,\n",
              "              'head': 2.001,\n",
              "              'horse': 1.001,\n",
              "              'journeyman': 1.001,\n",
              "              'lion': 1.001,\n",
              "              'looker': 1.001,\n",
              "              'mace': 1.001,\n",
              "              'man': 3.001,\n",
              "              'mass': 1.001,\n",
              "              'material': 1.001,\n",
              "              'means': 1.001,\n",
              "              'merchant': 1.001,\n",
              "              'mildly': 1.001,\n",
              "              'miller': 1.001,\n",
              "              'model': 1.001,\n",
              "              'modern': 1.001,\n",
              "              'monstrous': 1.001,\n",
              "              'mower': 1.001,\n",
              "              'mule': 1.001,\n",
              "              'murderer': 1.001,\n",
              "              'new': 1.001,\n",
              "              'particular': 1.001,\n",
              "              'passenger': 4.0009999999999994,\n",
              "              'pendulum': 1.001,\n",
              "              'permanent': 1.001,\n",
              "              'picked': 1.001,\n",
              "              'pike': 1.001,\n",
              "              'pile': 1.001,\n",
              "              'pilot': 3.001,\n",
              "              'portent': 1.001,\n",
              "              'rather': 2.001,\n",
              "              'real': 1.001,\n",
              "              'regular': 1.001,\n",
              "              'ripple': 1.001,\n",
              "              'sagacious': 1.001,\n",
              "              'sailor': 3.001,\n",
              "              'sea': 1.001,\n",
              "              'sensible': 1.001,\n",
              "              'set': 1.001,\n",
              "              'signal': 1.001,\n",
              "              'simple': 1.001,\n",
              "              'single': 2.001,\n",
              "              'slave': 1.001,\n",
              "              'small': 1.001,\n",
              "              'solid': 1.001,\n",
              "              'solitary': 1.001,\n",
              "              'sort': 3.001,\n",
              "              'species': 1.001,\n",
              "              'spice': 1.001,\n",
              "              'street': 1.001,\n",
              "              'substitute': 1.001,\n",
              "              'surveyor': 1.001,\n",
              "              'swashing': 1.001,\n",
              "              'tender': 1.001,\n",
              "              'thimbleful': 1.001,\n",
              "              'tossed': 1.001,\n",
              "              'traveller': 1.001,\n",
              "              'vessel': 1.001,\n",
              "              'wash': 1.001,\n",
              "              'weaver': 1.001,\n",
              "              'whaleman': 1.001,\n",
              "              'whistling': 1.001,\n",
              "              'white': 1.001,\n",
              "              'whole': 1.001,\n",
              "              'widow': 1.001,\n",
              "              'young': 1.001}))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hqc6nlL4Fui8"
      },
      "source": [
        "We can now generate non-sensical sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG-Cwz-uFui9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b7a1ae7-dda4-4b44-cfc5-14244f2e7dea"
      },
      "source": [
        "print(generate())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "And that is true , or how do you know ;-- merry ' s ebon head showed like a marble sepulchre ; though but a moment he chanced to see him again upon unknown rocks and snowy breakers .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MStsWKWTFujI"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Modify generate to take any number of initial words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR_r9GAe1ZnR"
      },
      "source": [
        "def generate_any(words=''):\r\n",
        "    result = [START, START]\r\n",
        "    for word in words.split():\r\n",
        "      result.append(word)\r\n",
        "    next_word = sample_next_word(result[-2], result[-1])\r\n",
        "    result.append(next_word)\r\n",
        "    while next_word != STOP:\r\n",
        "        next_word = sample_next_word(result[-2], result[-1])\r\n",
        "        result.append(next_word)\r\n",
        "    \r\n",
        "    return ' '.join(result[2:-1])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7CtdgnS1aEB",
        "outputId": "04b49dc3-4d80-4802-8b7d-0a8274d84ae7"
      },
      "source": [
        "print(generate_any('I want'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I want to see whether the fabled heavens with all the while ; to some utterly unknown to artists ; and finally descend into the frighted air ; then seemed to speak .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy8RESJU5Olv",
        "outputId": "735e35a6-3064-4a00-d95e-e17eec7e4ab9"
      },
      "source": [
        "print(generate_any('I will'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I will do ;\" for I will dismember my dismemberer .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCgjSXuy9RiU",
        "outputId": "a3d0ce8f-f97b-476a-f277-b85bb46f03bf"
      },
      "source": [
        "print(generate_any('my'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my God in obeying him !\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYItkm2V9ofV",
        "outputId": "5b10e1c4-d838-43e2-f8d7-049df3a62ff5"
      },
      "source": [
        "print(generate_any())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For even so , I ' ll twitch you off soon .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE1GCdYlFujP"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Extend the code above to arbitray $n$-gram sizes. Use another corpus to try it with $n=4$.\n",
        "\n",
        "It might be helpful to use a `class` for the LM, make the smoothing a parameter, `counts` a class property, and add a function `fit()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f97lkbMaFujQ"
      },
      "source": [
        "# Your code here\r\n",
        "\r\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNVRNgWaarTU"
      },
      "source": [
        "import wget\n",
        "url = 'https://raw.githubusercontent.com/dirkhovy/NLPclass/master/data/tweets_en.txt'\n",
        "wget.download(url, 'tweets_en.txt')\n",
        "tweets = [line.strip() for line in open('tweets_en.txt', encoding='utf8')]\n",
        " \n",
        "lm = LM(smoothing=0.001, n_grams_size=4)\n",
        "lm.fit(document=tweets)\n",
        "print(np.unique([lm.generate([\"Trump\",\"should\",\"think\",\"about\"]) \n",
        " for _ in range(10)]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}