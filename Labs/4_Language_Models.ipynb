{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "4_Language_Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8BGYonOGP0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebff92bb-0836-4a36-aee3-41ec420ab080"
      },
      "source": [
        "! pip install wget\n",
        "import wget"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=fde5d92b8bdce2ce7ae9f134e3b4d9a2429030caa7e97c550cdfd92a4c75a68b\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJjCXG1IGPdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6e798535-0881-480a-b533-362e5184e6fb"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/dirkhovy/NLPclass/master/data/moby_dick.txt'\n",
        "wget.download(url, 'moby_dick.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'moby_dick.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8EH2_u-Fugs"
      },
      "source": [
        "# Language Models\n",
        "\n",
        "Let's start with a simple, Laplace-smoothed trigram model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U00eZfVGFugw"
      },
      "source": [
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "smoothing = 0.001 # a factor helps the model to deal with unknown words\n",
        "START = '_***_'\n",
        "STOP = '_STOP_'\n",
        "\n",
        "# map from (u, v) to w = (w|u,v)\n",
        "# a dict that counts how many times we see a trigram, we will count from 0.001 not 0\n",
        "counts = defaultdict(lambda: defaultdict(lambda: smoothing))\n",
        "\n",
        "# fit data on corpus\n",
        "corpus = [line.strip().split() for line in open('moby_dick.txt')]\n",
        "\n",
        "# collect counts for MLE\n",
        "for sentence in corpus:\n",
        "    # include special tokens for start and the end of sentence\n",
        "    tokens = [START, START] + sentence + [STOP]\n",
        "    for u, v, w in nltk.ngrams(tokens, 3):\n",
        "        counts[(u, v)][w] += 1\n",
        "\n",
        "def logP(u, v, w): \n",
        "    \"\"\"\n",
        "    compute the log probability of a trigram\n",
        "    (u,v,w) => P(w|u,v) = c(u,v,w) / SUM(c(u,v,*))\n",
        "    \"\"\"\n",
        "    return np.log(counts[(u, v)][w]) - np.log(sum(counts[(u, v)].values()))\n",
        "\n",
        "def sentence_logP(S):\n",
        "    \"\"\"\n",
        "    score a sentence in log likelihood with chain rule\n",
        "    S: list(str)\n",
        "    \"\"\"\n",
        "    tokens = [START, START] + S + [STOP]\n",
        "    return sum([logP(u, v, w) for u, v, w in nltk.ngrams(tokens, 3)])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF42v_H7ufxb",
        "outputId": "ca09299d-8312-4450-d641-d34b6bc0bfec"
      },
      "source": [
        "counts[('because','he')]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>.<locals>.<lambda>>,\n",
              "            {'always': 1.001,\n",
              "             'could': 1.001,\n",
              "             'had': 2.001,\n",
              "             'happens': 1.001,\n",
              "             'is': 1.001,\n",
              "             'knows': 1.001,\n",
              "             'seemed': 1.001,\n",
              "             'treated': 1.001,\n",
              "             'tucks': 1.001,\n",
              "             'wanted': 1.001,\n",
              "             'was': 2.001})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoFO0lO1FuhA"
      },
      "source": [
        "We can now score arbitrary sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwJBkbQrFuhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e75c8db-d87e-469e-e924-afeffca9dd3d"
      },
      "source": [
        "sentence_logP('Captain Ahab is a man .'.split())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-27.92672048112014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybbofi_lkgFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee982ee6-2bfc-43e5-bff0-67fc01f4cd76"
      },
      "source": [
        "counts[('you','are')]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function __main__.<lambda>.<locals>.<lambda>>,\n",
              "            {',': 1.001,\n",
              "             '.': 1.001,\n",
              "             'all': 1.001,\n",
              "             'an': 1.001,\n",
              "             'but': 1.001,\n",
              "             'close': 1.001,\n",
              "             'dead': 1.001,\n",
              "             'determined': 1.001,\n",
              "             'eating': 1.001,\n",
              "             'experienced': 1.001,\n",
              "             'goin': 1.001,\n",
              "             'heavy': 1.001,\n",
              "             'in': 3.001,\n",
              "             'just': 1.001,\n",
              "             'mistaken': 1.001,\n",
              "             'now': 3.001,\n",
              "             'only': 1.001,\n",
              "             'pitched': 1.001,\n",
              "             'quick': 1.001,\n",
              "             'skylarking': 1.001,\n",
              "             'speaking': 1.001,\n",
              "             'struck': 1.001,\n",
              "             'telling': 1.001,\n",
              "             'that': 1.001,\n",
              "             'the': 1.001})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqSc6ksAipHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99d8ab14-3177-4aab-f75c-f69a4e9be648"
      },
      "source": [
        "sum(counts[('you','are')].values())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29.02500000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz04HP-vFuh8"
      },
      "source": [
        "## Activity\n",
        "Implement the perplexity measure for a given corpus, and try it with two LM with different smoothing parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIPDCI6eFuh_"
      },
      "source": [
        "$$perplexity = 2^{-\\sum_{x \\in X} p(x) \\log p(x)}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTSRyIN4FuiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7716cc10-e41c-4e43-c314-0d74f8a0b5d3"
      },
      "source": [
        "def get_perplexity(corpus):\n",
        "    \"\"\"\n",
        "    perplexity = 2^-entropy(X)\n",
        "    entropy = -sum(p(x) *log(p(x)))\n",
        "    \"\"\"\n",
        "    entropy = 0.0\n",
        "    for sentence in corpus:\n",
        "        sentence_log_prob = sentence_logP(sentence)\n",
        "        sentence_entropy = np.exp(sentence_log_prob) * sentence_log_prob\n",
        "        entropy += sentence_entropy\n",
        "        \n",
        "    perplexity = 2 ** -entropy\n",
        "    return perplexity\n",
        "\n",
        "print(get_perplexity(corpus))\n",
        "#4.12 means the model will choose 4 words !!!   , when inferring a new word "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.118431257864399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGfhZxlhFuiL"
      },
      "source": [
        "## Generation\n",
        "\n",
        "We can re-use the counts to generate language:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL9kdmiEFuiN"
      },
      "source": [
        "def generate():\n",
        "    result = [START, START]\n",
        "    next_word = sample_next_word(result[-2], result[-1])\n",
        "    result.append(next_word)\n",
        "    while next_word != STOP:\n",
        "        next_word = sample_next_word(result[-2], result[-1])\n",
        "        result.append(next_word)\n",
        "    \n",
        "    return ' '.join(result[2:-1])\n",
        "\n",
        "def sample_next_word(u, v):\n",
        "    \"\"\"\n",
        "    sample a word w based on the history (u, v) --> the length of history is 2\n",
        "    \"\"\"\n",
        "    # separate word and their counts into separate variables\n",
        "    keys, values = zip(*counts[(u, v)].items())\n",
        "    \n",
        "    # normalize the counts into a probability distribution\n",
        "    values = np.array(values)\n",
        "    values /= values.sum() # create probability distro\n",
        "     \n",
        "    # this is the meat of the function\n",
        "    sample = np.random.multinomial(1, values) # pick one position\n",
        "    \n",
        "    return keys[np.argmax(sample)]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG51FZMWylr5",
        "outputId": "049c392c-e845-4d54-bbb2-b7ee2d0327e4"
      },
      "source": [
        "keys , values = zip(*counts[(START,START)].items())\n",
        "#keys, values #these are the possible start words with their counts\n",
        "keys , values = zip(*counts[('you','are')].items())\n",
        "values = np.array(values)\n",
        "values /= values.sum()\n",
        "values # the probability distribution for the keys"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10339363, 0.03448751, 0.03448751, 0.03448751, 0.03448751,\n",
              "       0.03448751, 0.03448751, 0.03448751, 0.03448751, 0.03448751,\n",
              "       0.03448751, 0.03448751, 0.10339363, 0.03448751, 0.03448751,\n",
              "       0.03448751, 0.03448751, 0.03448751, 0.03448751, 0.03448751,\n",
              "       0.03448751, 0.03448751, 0.03448751, 0.03448751, 0.03448751])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGPhqPGZz-UV",
        "outputId": "fb48f1cc-02b1-43b0-8260-38bebfdb842c"
      },
      "source": [
        "sample = np.random.multinomial(1, values) \n",
        "sample"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EO1OmOS-z-Wc",
        "outputId": "42c265a2-3207-4679-c32b-265e89f0281a"
      },
      "source": [
        "keys[np.argmax(sample)]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'speaking'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_atwtcfyemb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "MsqbTApXFuiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857fa48c-4cdf-4b25-c16a-31ea08e8ad90"
      },
      "source": [
        "for i in range(50):\n",
        "    keys, values = zip(*counts[('you','are')].items())\n",
        "    values = np.array(values)\n",
        "    values /= values.sum()\n",
        "    sample = np.random.multinomial(1, values)\n",
        "    print(keys[np.argmax(sample)])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "an\n",
            "close\n",
            "in\n",
            "pitched\n",
            "goin\n",
            "eating\n",
            "only\n",
            "the\n",
            "in\n",
            "now\n",
            "now\n",
            "mistaken\n",
            "dead\n",
            "but\n",
            "goin\n",
            "but\n",
            ",\n",
            "now\n",
            "determined\n",
            "experienced\n",
            "mistaken\n",
            "pitched\n",
            "all\n",
            ".\n",
            "only\n",
            "dead\n",
            "struck\n",
            "all\n",
            "only\n",
            "pitched\n",
            "dead\n",
            "goin\n",
            "skylarking\n",
            "eating\n",
            "heavy\n",
            "an\n",
            "in\n",
            "but\n",
            "eating\n",
            "in\n",
            "but\n",
            "now\n",
            "speaking\n",
            "dead\n",
            ".\n",
            "in\n",
            "in\n",
            "in\n",
            "close\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9glS5aGFFuiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab6d3e1-2caa-49bb-a2ab-617f7658bb94"
      },
      "source": [
        "sample_next_word('as', 'a'), counts[('as', 'a')]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('pile',\n",
              " defaultdict(<function __main__.<lambda>.<locals>.<lambda>>,\n",
              "             {'Commodore': 1.001,\n",
              "              'Dish': 1.001,\n",
              "              'Latin': 1.001,\n",
              "              'Roman': 1.001,\n",
              "              'backwoodsman': 1.001,\n",
              "              'bat': 1.001,\n",
              "              'birch': 1.001,\n",
              "              'body': 2.001,\n",
              "              'candidate': 1.001,\n",
              "              'cat': 1.001,\n",
              "              'civilized': 1.001,\n",
              "              'clam': 1.001,\n",
              "              'clock': 1.001,\n",
              "              'coffin': 1.001,\n",
              "              'conceited': 1.001,\n",
              "              'cook': 1.001,\n",
              "              'corpse': 1.001,\n",
              "              'country': 1.001,\n",
              "              'cricket': 1.001,\n",
              "              'crucible': 1.001,\n",
              "              'dead': 1.001,\n",
              "              'dinnerless': 1.001,\n",
              "              'dragon': 1.001,\n",
              "              'drawing': 1.001,\n",
              "              'dromedary': 1.001,\n",
              "              'fin': 1.001,\n",
              "              'flavorish': 1.001,\n",
              "              'fly': 1.001,\n",
              "              'foreshadowing': 1.001,\n",
              "              'frigate': 1.001,\n",
              "              'general': 6.0009999999999994,\n",
              "              'geologist': 1.001,\n",
              "              'giraffe': 1.001,\n",
              "              'god': 1.001,\n",
              "              'golden': 1.001,\n",
              "              'green': 1.001,\n",
              "              'harpoon': 1.001,\n",
              "              'harpooneer': 1.001,\n",
              "              'head': 2.001,\n",
              "              'horse': 1.001,\n",
              "              'journeyman': 1.001,\n",
              "              'lion': 1.001,\n",
              "              'looker': 1.001,\n",
              "              'mace': 1.001,\n",
              "              'man': 3.001,\n",
              "              'mass': 1.001,\n",
              "              'material': 1.001,\n",
              "              'means': 1.001,\n",
              "              'merchant': 1.001,\n",
              "              'mildly': 1.001,\n",
              "              'miller': 1.001,\n",
              "              'model': 1.001,\n",
              "              'modern': 1.001,\n",
              "              'monstrous': 1.001,\n",
              "              'mower': 1.001,\n",
              "              'mule': 1.001,\n",
              "              'murderer': 1.001,\n",
              "              'new': 1.001,\n",
              "              'particular': 1.001,\n",
              "              'passenger': 4.0009999999999994,\n",
              "              'pendulum': 1.001,\n",
              "              'permanent': 1.001,\n",
              "              'picked': 1.001,\n",
              "              'pike': 1.001,\n",
              "              'pile': 1.001,\n",
              "              'pilot': 3.001,\n",
              "              'portent': 1.001,\n",
              "              'rather': 2.001,\n",
              "              'real': 1.001,\n",
              "              'regular': 1.001,\n",
              "              'ripple': 1.001,\n",
              "              'sagacious': 1.001,\n",
              "              'sailor': 3.001,\n",
              "              'sea': 1.001,\n",
              "              'sensible': 1.001,\n",
              "              'set': 1.001,\n",
              "              'signal': 1.001,\n",
              "              'simple': 1.001,\n",
              "              'single': 2.001,\n",
              "              'slave': 1.001,\n",
              "              'small': 1.001,\n",
              "              'solid': 1.001,\n",
              "              'solitary': 1.001,\n",
              "              'sort': 3.001,\n",
              "              'species': 1.001,\n",
              "              'spice': 1.001,\n",
              "              'street': 1.001,\n",
              "              'substitute': 1.001,\n",
              "              'surveyor': 1.001,\n",
              "              'swashing': 1.001,\n",
              "              'tender': 1.001,\n",
              "              'thimbleful': 1.001,\n",
              "              'tossed': 1.001,\n",
              "              'traveller': 1.001,\n",
              "              'vessel': 1.001,\n",
              "              'wash': 1.001,\n",
              "              'weaver': 1.001,\n",
              "              'whaleman': 1.001,\n",
              "              'whistling': 1.001,\n",
              "              'white': 1.001,\n",
              "              'whole': 1.001,\n",
              "              'widow': 1.001,\n",
              "              'young': 1.001}))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hqc6nlL4Fui8"
      },
      "source": [
        "We can now generate non-sensical sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG-Cwz-uFui9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac3e203-ba23-4e29-d7ca-f5696d6a53cd"
      },
      "source": [
        "print(generate())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It is by the stranger ' s nails are divided into wrought nails and cut nails ; so that there ' s the word with a pealing exultation and joy of Jonah teaches to all sperm whales , the Commodore ' s stern came into conspicuous relief .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MStsWKWTFujI"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Modify generate to take any number of initial words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR_r9GAe1ZnR"
      },
      "source": [
        "def generate_any(words=''):\n",
        "    result = [START, START]\n",
        "    for word in words.split():\n",
        "      result.append(word)\n",
        "    next_word = sample_next_word(result[-2], result[-1])\n",
        "    result.append(next_word)\n",
        "    while next_word != STOP:\n",
        "        next_word = sample_next_word(result[-2], result[-1])\n",
        "        result.append(next_word)\n",
        "    \n",
        "    return ' '.join(result[2:-1])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7CtdgnS1aEB",
        "outputId": "2899759d-eca1-4140-b7ae-24e95d985223"
      },
      "source": [
        "print(generate_any('I want'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I want it ; but till you say aye to me as a sailor , but that will point as true as any .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy8RESJU5Olv",
        "outputId": "2be4fb36-09e6-41ed-b333-94303571316e"
      },
      "source": [
        "print(generate_any('I will'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I will here venture upon a thwart of his companions had mounted to its latter formations exceed in size , varying from fifteen to twenty - six arms , sir .\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCgjSXuy9RiU",
        "outputId": "af0049b4-c4f8-47cb-9136-bdf97b1f5aa1"
      },
      "source": [
        "print(generate_any('my'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my spine , all the Pacific , and directions from Mrs . Hussey wore a red cotton velvet vest and the great White Whale fully incites the hearts of mountains bathed in their beds ; the headlong , sled - like sea heaved up their anchors with that almost every twenty - four hours , when -- THERE SHE BLOWS !-- the deck - table are thus cannibally carving each other better than royal blood there .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYItkm2V9ofV",
        "outputId": "fe448868-86a0-424e-ac04-4d3a13c613a3"
      },
      "source": [
        "print(generate_any())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "By all accounts Tarshish could have been hunted by man ), but in the tub oarsman ( him seated by the old man , his body , there are gestures in it .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE1GCdYlFujP"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Extend the code above to arbitray $n$-gram sizes. Use another corpus to try it with $n=4$.\n",
        "\n",
        "It might be helpful to use a `class` for the LM, make the smoothing a parameter, `counts` a class property, and add a function `fit()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f97lkbMaFujQ"
      },
      "source": [
        "# Your code here\n",
        "\n",
        "class LM():\n",
        "\n",
        "  def __init__(self, smoothing, n_grams_size):\n",
        "    self.n_grams_size_ = n_grams_size\n",
        "    self.counts = defaultdict(lambda: defaultdict(lambda: smoothing))\n",
        "\n",
        "  def fit(self,document):\n",
        "    self.corpus = [line.strip().split() for line in document]\n",
        "    for sentence in self.corpus:\n",
        "      tokens = [START] * (self.n_grams_size_ -1 ) + sentence + [STOP]\n",
        "      for n in nltk.ngrams(tokens, self.n_grams_size_):\n",
        "        self.counts[n[:-1]][n[-1]] += 1\n",
        "\n",
        "  def sample_next_word(self,nwords):\n",
        "    keys, values = zip(*self.counts[tuple(nwords)].items())\n",
        "    values = np.array(values)\n",
        "    values /= values.sum() \n",
        "    \n",
        "    sample = np.random.multinomial(1, values) # pick one position\n",
        "    \n",
        "    return keys[np.argmax(sample)]\n",
        "\n",
        "  def generate(self, words=''):\n",
        "    result = [START] * (self.n_grams_size_ - 1)\n",
        "    for word in words:\n",
        "      result.append(word)\n",
        "    next_word = self.sample_next_word(nwords = result[- (self.n_grams_size_ - 1):])\n",
        "    result.append(next_word)\n",
        "    while next_word != STOP:\n",
        "        next_word = self.sample_next_word(nwords = result[- (self.n_grams_size_ - 1):])\n",
        "        result.append(next_word)\n",
        "    \n",
        "    return ' '.join(result[(self.n_grams_size_ - 1):-1])\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNVRNgWaarTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e5272d9-27ad-4215-f081-c9339e8def5f"
      },
      "source": [
        "import wget\n",
        "url = 'https://raw.githubusercontent.com/dirkhovy/NLPclass/master/data/tweets_en.txt'\n",
        "wget.download(url, 'tweets_en.txt')\n",
        "tweets = [line.strip() for line in open('tweets_en.txt', encoding='utf8')]\n",
        " \n",
        "lm = LM(smoothing=0.001, n_grams_size=4)\n",
        "lm.fit(document=tweets)\n",
        "print(np.unique([lm.generate(words=[\"Trump\",\"should\",\"think\",\"about\"]) \n",
        " for _ in range(10)]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Trump should think about going and buying some food!!'\n",
            " 'Trump should think about going to Bulgaria in October #willibeabletolivethere'\n",
            " 'Trump should think about going to the gym anyway, dedication or wit?'\n",
            " 'Trump should think about going to the match #buzzzzn'\n",
            " 'Trump should think about going to uni to study something']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}